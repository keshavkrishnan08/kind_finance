{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KTND-Finance: Full Experiment Pipeline (v1.5.3)\n",
    "\n",
    "### How to run:\n",
    "1. **Cell 1** (Setup) -- Install deps + clone repo (~2 min)\n",
    "2. **Cell 2** (Pipeline) -- Full pipeline + multi-seed + figures (~2-3 hours)\n",
    "3. **Cell 3** (Ablations) -- Ablation study + Brownian gyrator (~6 hours, optional)\n",
    "4. **Cell 4** (View) -- Display all figures\n",
    "5. **Cell 5** (Download) -- Zip all results\n",
    "\n",
    "### What changed (v1.5.3):\n",
    "- **Lower regularization** -- beta_orth 0.001 (was 0.005), gamma_reg 1e-6 (was 1e-5)\n",
    "- **More univariate modes** -- n_modes 8 (was 5) for narrower entropy gap\n",
    "- **Multiasset robustness** -- full 7-test statistical battery on multiasset model too\n",
    "- **Mode-aware results** -- robustness saves per-mode (statistical_tests.json / _multiasset.json)\n",
    "\n",
    "### Previous (v1.5.2):\n",
    "- 7 statistical tests (added time-reversal asymmetry)\n",
    "- Cohen's d effect sizes on permutation test\n",
    "- 1000 permutations, BIC model selection for HMM\n",
    "- LR 3e-4, 800 epochs, 15 multiasset modes\n",
    "\n",
    "### Notes:\n",
    "- Set runtime to **GPU (T4)**: Runtime -> Change runtime type -> T4 GPU\n",
    "- Cell 2 and Cell 3 are **independent** -- if Colab disconnects during Cell 3, Cell 2 outputs are preserved\n",
    "- Cell 3 is **resume-safe** -- ablations save after each variant, so re-running picks up where it left off\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 1. Setup (install + clone + verify) - ~2 min\n",
    "\n",
    "# Install missing dependencies (torch/numpy/pandas/scipy/sklearn/matplotlib are pre-installed)\n",
    "!pip install -q yfinance>=1.0.0 hmmlearn>=0.3.0 statsmodels>=0.14.0 arch>=6.0.0 pyyaml>=6.0\n",
    "\n",
    "# Clone repo\n",
    "import os, sys\n",
    "REPO_URL = \"https://github.com/keshavkrishnan08/kind_finance.git\"\n",
    "REPO_DIR = \"/content/ktnd_finance\"\n",
    "\n",
    "if os.path.exists(REPO_DIR):\n",
    "    !cd {REPO_DIR} && git pull\n",
    "else:\n",
    "    !git clone {REPO_URL} {REPO_DIR}\n",
    "\n",
    "os.chdir(REPO_DIR)\n",
    "sys.path.insert(0, REPO_DIR)\n",
    "\n",
    "# Verify\n",
    "import torch, numpy as np\n",
    "from src.model.vampnet import NonEquilibriumVAMPNet\n",
    "print(f\"Python {sys.version.split()[0]} | PyTorch {torch.__version__} | \"\n",
    "      f\"CUDA: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}\")\n",
    "print(\"Setup complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 2. Run pipeline + multi-seed + figures (~2-3 hours)\n",
    "\n",
    "import subprocess, time, json, os, sys, glob\n",
    "\n",
    "# ==========================================================================\n",
    "# PATHS\n",
    "# ==========================================================================\n",
    "REPO_DIR = \"/content/ktnd_finance\"\n",
    "OUTPUT_DIR = \"/content/ktnd_finance/outputs\"\n",
    "RESULTS_DIR = \"/content/ktnd_finance/outputs/results\"\n",
    "MODELS_DIR = \"/content/ktnd_finance/outputs/models\"\n",
    "FIGURES_DIR = \"/content/ktnd_finance/outputs/figures\"\n",
    "DATA_DIR = \"/content/ktnd_finance/data\"\n",
    "\n",
    "for d in [OUTPUT_DIR, RESULTS_DIR, MODELS_DIR, FIGURES_DIR]:\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "os.chdir(REPO_DIR)\n",
    "python = sys.executable\n",
    "\n",
    "print(f\"Python: {python}\")\n",
    "print(f\"CWD: {os.getcwd()}\")\n",
    "print(f\"Repo dir exists: {os.path.exists(REPO_DIR)}\")\n",
    "print(f\"src/ exists: {os.path.isdir(os.path.join(REPO_DIR, 'src'))}\")\n",
    "print(f\"experiments/ exists: {os.path.isdir(os.path.join(REPO_DIR, 'experiments'))}\")\n",
    "print(f\"config/ exists: {os.path.isdir(os.path.join(REPO_DIR, 'config'))}\")\n",
    "\n",
    "def run(name, cmd, check_files=None):\n",
    "    \"\"\"Run a stage, print output, verify files.\"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"  STAGE: {name}\")\n",
    "    print(f\"  CMD: {cmd}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    t0 = time.time()\n",
    "    result = subprocess.run(cmd, shell=True, cwd=REPO_DIR,\n",
    "                            capture_output=True, text=True)\n",
    "    elapsed = time.time() - t0\n",
    "\n",
    "    if result.stdout:\n",
    "        for line in result.stdout.strip().split('\\n'):\n",
    "            print(f\"  {line}\")\n",
    "\n",
    "    if result.returncode != 0:\n",
    "        print(f\"\\n  === STDERR ===\")\n",
    "        if result.stderr:\n",
    "            for line in result.stderr.strip().split('\\n'):\n",
    "                print(f\"  ! {line}\")\n",
    "        print(f\"  >> {name}: FAILED (exit code {result.returncode}, {elapsed/60:.1f} min)\")\n",
    "        return False\n",
    "\n",
    "    if result.stderr:\n",
    "        stderr_lines = result.stderr.strip().split('\\n')\n",
    "        error_lines = [l for l in stderr_lines if 'Error' in l or 'Exception' in l or 'Traceback' in l]\n",
    "        if error_lines:\n",
    "            print(f\"  === STDERR (errors) ===\")\n",
    "            for line in error_lines:\n",
    "                print(f\"  ! {line}\")\n",
    "\n",
    "    if check_files:\n",
    "        missing = [f for f in check_files if not os.path.exists(f)]\n",
    "        if missing:\n",
    "            print(f\"  WARNING: Missing expected output files:\")\n",
    "            for f in missing:\n",
    "                print(f\"    MISSING: {f}\")\n",
    "            if result.stderr:\n",
    "                for line in result.stderr.strip().split('\\n')[-30:]:\n",
    "                    print(f\"  ! {line}\")\n",
    "            print(f\"  >> {name}: INCOMPLETE ({elapsed/60:.1f} min)\")\n",
    "            return False\n",
    "        for f in check_files:\n",
    "            sz = os.path.getsize(f)\n",
    "            print(f\"  OK: {os.path.basename(f)} ({sz:,} bytes)\")\n",
    "\n",
    "    print(f\"  >> {name}: OK ({elapsed/60:.1f} min)\")\n",
    "    return True\n",
    "\n",
    "pipeline_start = time.time()\n",
    "results = {}\n",
    "\n",
    "# ======================================================================\n",
    "# PART A: FULL PIPELINE (~2-3 hours)\n",
    "# ======================================================================\n",
    "print(f\"\\n{'#'*70}\")\n",
    "print(f\"#  PART A: FULL PIPELINE\")\n",
    "print(f\"#  Order: tests -> download -> train(uni+multi) -> baselines ->\")\n",
    "print(f\"#         rolling -> robustness(needs rolling output) -> figures\")\n",
    "print(f\"{'#'*70}\")\n",
    "\n",
    "# --- Stage 1: Quick tests ---\n",
    "results['tests'] = run('Quick tests',\n",
    "    f'{python} -m pytest tests/ -q --tb=short -k \"not test_synthetic\"')\n",
    "\n",
    "# --- Stage 2: Download data ---\n",
    "results['download'] = run('Download data',\n",
    "    f'{python} {REPO_DIR}/data/download.py --mode all',\n",
    "    check_files=[f'{DATA_DIR}/prices.csv', f'{DATA_DIR}/vix.csv'])\n",
    "\n",
    "# --- Stage 3: Train univariate ---\n",
    "# NOTE: --config default.yaml ensures all loss weights/training params are loaded.\n",
    "# Mode-specific overrides (n_modes=5, hidden_dims, batch_size) merge from univariate.yaml.\n",
    "results['train_uni'] = run('Train univariate (SPY)',\n",
    "    f'{python} {REPO_DIR}/experiments/run_main.py'\n",
    "    f' --config config/default.yaml --mode univariate --seed 42'\n",
    "    f' --output-dir {OUTPUT_DIR}',\n",
    "    check_files=[\n",
    "        f'{RESULTS_DIR}/analysis_results.json',\n",
    "        f'{RESULTS_DIR}/eigenvalues.csv',\n",
    "        f'{RESULTS_DIR}/entropy_decomposition.csv',\n",
    "        f'{RESULTS_DIR}/irreversibility_field.npy',\n",
    "        f'{MODELS_DIR}/vampnet_univariate.pt',\n",
    "    ])\n",
    "\n",
    "# --- Stage 4: Train multiasset ---\n",
    "results['train_multi'] = run('Train multiasset (11 ETFs)',\n",
    "    f'{python} {REPO_DIR}/experiments/run_main.py'\n",
    "    f' --config config/default.yaml --mode multiasset --seed 42'\n",
    "    f' --output-dir {OUTPUT_DIR}',\n",
    "    check_files=[f'{RESULTS_DIR}/analysis_results_multiasset.json',\n",
    "                 f'{MODELS_DIR}/vampnet_multiasset.pt'])\n",
    "\n",
    "# --- Stage 5: Baselines ---\n",
    "results['baselines'] = run('Baselines',\n",
    "    f'{python} {REPO_DIR}/experiments/run_baselines.py'\n",
    "    f' --config config/default.yaml --output-dir {RESULTS_DIR}',\n",
    "    check_files=[f'{RESULTS_DIR}/baseline_comparison.csv'])\n",
    "\n",
    "# --- Stage 6: Rolling (BEFORE robustness -- Granger needs spectral_gap_timeseries.csv) ---\n",
    "results['rolling'] = run('Rolling spectral analysis',\n",
    "    f'{python} {REPO_DIR}/experiments/run_rolling.py'\n",
    "    f' --config config/default.yaml --mode univariate'\n",
    "    f' --checkpoint {MODELS_DIR}/vampnet_univariate.pt'\n",
    "    f' --output-dir {RESULTS_DIR}',\n",
    "    check_files=[f'{RESULTS_DIR}/spectral_gap_timeseries.csv'])\n",
    "\n",
    "# --- Stage 7: Robustness (AFTER rolling -- Granger needs spectral_gap_timeseries.csv) ---\n",
    "results['robustness'] = run('Robustness tests',\n",
    "    f'{python} {REPO_DIR}/experiments/run_robustness.py'\n",
    "    f' --config config/default.yaml --mode univariate'\n",
    "    f' --checkpoint {MODELS_DIR}/vampnet_univariate.pt'\n",
    "    f' --output-dir {RESULTS_DIR}',\n",
    "    check_files=[f'{RESULTS_DIR}/statistical_tests.json'])\n",
    "\n",
    "# --- Stage 7b: Robustness multiasset (stronger non-eq signal, 12/15 complex modes) ---\n",
    "results['robustness_multi'] = run('Robustness tests (multiasset)',\n",
    "    f'{python} {REPO_DIR}/experiments/run_robustness.py'\n",
    "    f' --config config/default.yaml --mode multiasset'\n",
    "    f' --checkpoint {MODELS_DIR}/vampnet_multiasset.pt'\n",
    "    f' --output-dir {RESULTS_DIR}',\n",
    "    check_files=[f'{RESULTS_DIR}/statistical_tests_multiasset.json'])\n",
    "\n",
    "# --- Stage 8: Figures (script) ---\n",
    "results['figures'] = run('Generate figures (script)',\n",
    "    f'{python} {REPO_DIR}/experiments/run_figures.py'\n",
    "    f' --results-dir {RESULTS_DIR} --figures-dir {FIGURES_DIR}')\n",
    "\n",
    "# --- Stage 9: Figures (inline fallback) ---\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"  GENERATING FIGURES INLINE (FALLBACK)\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "n_figs = 0\n",
    "\n",
    "for mode_tag, label in [(\"univariate\", \"Univariate (SPY)\"), (\"multiasset\", \"Multiasset\")]:\n",
    "    ap = f\"{RESULTS_DIR}/analysis_results_{mode_tag}.json\"\n",
    "    if not os.path.exists(ap):\n",
    "        continue\n",
    "    with open(ap) as f:\n",
    "        ar = json.load(f)\n",
    "\n",
    "    er, ei = ar.get(\"eigenvalues_real\"), ar.get(\"eigenvalues_imag\")\n",
    "    if er and ei:\n",
    "        er, ei = np.array(er), np.array(ei)\n",
    "        mags = np.sqrt(er**2 + ei**2)\n",
    "        fig, ax = plt.subplots(figsize=(7,7))\n",
    "        th = np.linspace(0, 2*np.pi, 300)\n",
    "        ax.plot(np.cos(th), np.sin(th), \"k--\", lw=0.8, alpha=0.5)\n",
    "        sc = ax.scatter(er, ei, c=mags, cmap=\"viridis\", edgecolors=\"k\", linewidths=0.4, s=80, zorder=3)\n",
    "        plt.colorbar(sc, ax=ax, label=\"|$\\\\lambda$|\")\n",
    "        for i, idx in enumerate(np.argsort(-mags)[:5]):\n",
    "            ax.annotate(f\"$\\\\lambda_{i}$\", (er[idx], ei[idx]), textcoords=\"offset points\", xytext=(8,8), fontsize=9)\n",
    "        ax.set_xlabel(\"Re($\\\\lambda$)\"); ax.set_ylabel(\"Im($\\\\lambda$)\")\n",
    "        ax.set_title(f\"Koopman Eigenvalue Spectrum -- {label}\"); ax.set_aspect(\"equal\"); ax.grid(True, alpha=0.3)\n",
    "        fig.savefig(f\"{FIGURES_DIR}/fig1_eigenvalue_spectrum_{mode_tag}.png\", dpi=300, bbox_inches=\"tight\"); plt.close(fig); n_figs += 1\n",
    "\n",
    "for csv_name, title, ycol in [\n",
    "    (\"eigenvalues.csv\", \"Eigenvalue Magnitudes\", \"magnitude\"),\n",
    "    (\"entropy_decomposition.csv\", \"Entropy Decomposition\", \"entropy_production\"),\n",
    "]:\n",
    "    p = f\"{RESULTS_DIR}/{csv_name}\"\n",
    "    if os.path.exists(p):\n",
    "        df = pd.read_csv(p)\n",
    "        if ycol in df.columns:\n",
    "            fig, ax = plt.subplots(figsize=(8,5))\n",
    "            ax.bar(df[\"mode\"], df[ycol], color=\"coral\" if \"entropy\" in csv_name else \"steelblue\", edgecolor=\"black\", lw=0.3)\n",
    "            ax.set_xlabel(\"Mode\"); ax.set_ylabel(ycol); ax.set_title(title); ax.grid(True, alpha=0.3, axis=\"y\")\n",
    "            fig.savefig(f\"{FIGURES_DIR}/fig_{csv_name.replace('.csv','')}.png\", dpi=300, bbox_inches=\"tight\"); plt.close(fig); n_figs += 1\n",
    "\n",
    "irp = f\"{RESULTS_DIR}/irreversibility_field.npy\"\n",
    "if os.path.exists(irp):\n",
    "    ir = np.load(irp, allow_pickle=True)\n",
    "    fig, ax = plt.subplots(figsize=(14,4))\n",
    "    ax.fill_between(range(len(ir)), ir, alpha=0.4, color=\"darkorange\"); ax.plot(ir, lw=0.5, color=\"darkorange\")\n",
    "    ax.set_xlabel(\"Time\"); ax.set_ylabel(\"$I(x)$\"); ax.set_title(\"Irreversibility Field\"); ax.grid(True, alpha=0.3)\n",
    "    fig.savefig(f\"{FIGURES_DIR}/fig_irreversibility_field.png\", dpi=300, bbox_inches=\"tight\"); plt.close(fig); n_figs += 1\n",
    "\n",
    "rcp = f\"{RESULTS_DIR}/spectral_gap_timeseries.csv\"\n",
    "if os.path.exists(rcp):\n",
    "    rdf = pd.read_csv(rcp)\n",
    "    if \"spectral_gap\" in rdf.columns:\n",
    "        fig, ax = plt.subplots(figsize=(14,5))\n",
    "        x = pd.to_datetime(rdf[\"center_date\"]) if \"center_date\" in rdf.columns else range(len(rdf))\n",
    "        ax.plot(x, rdf[\"spectral_gap\"], color=\"steelblue\", lw=1.0)\n",
    "        ax.set_xlabel(\"Date\"); ax.set_ylabel(\"Spectral Gap\"); ax.set_title(\"Rolling Spectral Gap\"); ax.grid(True, alpha=0.3)\n",
    "        fig.savefig(f\"{FIGURES_DIR}/fig_spectral_gap.png\", dpi=300, bbox_inches=\"tight\"); plt.close(fig); n_figs += 1\n",
    "\n",
    "bcp = f\"{RESULTS_DIR}/baseline_comparison.csv\"\n",
    "if os.path.exists(bcp):\n",
    "    bdf = pd.read_csv(bcp)\n",
    "    ms = [m for m in [\"nber_accuracy\",\"nber_f1\",\"nber_precision\",\"nber_recall\"] if m in bdf.columns]\n",
    "    if ms and \"method\" in bdf.columns:\n",
    "        fig, ax = plt.subplots(figsize=(10,6))\n",
    "        x = np.arange(len(bdf)); w = 0.8/len(ms)\n",
    "        for i, m in enumerate(ms):\n",
    "            ax.bar(x+i*w, bdf[m].astype(float), w, label=m.replace(\"nber_\",\"\").title(),\n",
    "                   color=[\"steelblue\",\"coral\",\"seagreen\",\"orchid\"][i%4], edgecolor=\"black\", lw=0.3)\n",
    "        ax.set_xticks(x+w*(len(ms)-1)/2); ax.set_xticklabels(bdf[\"method\"], rotation=15, ha=\"right\")\n",
    "        ax.set_ylabel(\"Score\"); ax.set_title(\"Baseline Comparison\"); ax.legend(); ax.set_ylim(0,1.05)\n",
    "        fig.savefig(f\"{FIGURES_DIR}/fig_baseline_comparison.png\", dpi=300, bbox_inches=\"tight\"); plt.close(fig); n_figs += 1\n",
    "\n",
    "print(f\"  Generated {n_figs} figures inline\")\n",
    "\n",
    "# ======================================================================\n",
    "# PART A2: MULTI-SEED ERROR BARS (5 seeds total, ~1.5 hours)\n",
    "# PRE requires error bars on main results. Run 4 additional seeds\n",
    "# for training + analysis only (baselines/rolling/figures use seed 42).\n",
    "# ======================================================================\n",
    "N_MAIN_SEEDS = 5\n",
    "EXTRA_SEEDS = [0, 1, 2, 3]  # + seed 42 from above = 5 total\n",
    "\n",
    "print(f\"\\n{'#'*70}\")\n",
    "print(f\"#  PART A2: MULTI-SEED ERROR BARS ({N_MAIN_SEEDS} seeds)\")\n",
    "print(f\"#  Running {len(EXTRA_SEEDS)} additional seeds + seed 42 from above\")\n",
    "print(f\"#  Only re-runs training + analysis (not baselines/rolling/figures)\")\n",
    "print(f\"{'#'*70}\")\n",
    "\n",
    "multi_seed_results = {}\n",
    "\n",
    "# Collect seed=42 results from the primary run\n",
    "for mode_tag in [\"univariate\", \"multiasset\"]:\n",
    "    ap = f\"{RESULTS_DIR}/analysis_results_{mode_tag}.json\"\n",
    "    if os.path.exists(ap):\n",
    "        with open(ap) as f:\n",
    "            multi_seed_results.setdefault(mode_tag, {})[42] = json.load(f)\n",
    "\n",
    "# Run extra seeds\n",
    "for seed in EXTRA_SEEDS:\n",
    "    seed_dir = f\"{OUTPUT_DIR}/seed_{seed}\"\n",
    "    seed_results = f\"{seed_dir}/results\"\n",
    "    seed_models = f\"{seed_dir}/models\"\n",
    "    os.makedirs(seed_results, exist_ok=True)\n",
    "    os.makedirs(seed_models, exist_ok=True)\n",
    "\n",
    "    for mode_tag in [\"univariate\", \"multiasset\"]:\n",
    "        # Check if already completed (resume-safe)\n",
    "        seed_ap = f\"{seed_results}/analysis_results_{mode_tag}.json\"\n",
    "        if os.path.exists(seed_ap):\n",
    "            print(f\"\\n  --- Seed {seed}, mode={mode_tag}: ALREADY DONE (resuming) ---\")\n",
    "            with open(seed_ap) as f:\n",
    "                multi_seed_results.setdefault(mode_tag, {})[seed] = json.load(f)\n",
    "            continue\n",
    "\n",
    "        print(f\"\\n  --- Seed {seed}, mode={mode_tag} ---\", flush=True)\n",
    "        ok = run(f'Seed {seed} {mode_tag}',\n",
    "            f'{python} {REPO_DIR}/experiments/run_main.py'\n",
    "            f' --config config/default.yaml --mode {mode_tag} --seed {seed}'\n",
    "            f' --output-dir {seed_dir}')\n",
    "\n",
    "        if os.path.exists(seed_ap):\n",
    "            with open(seed_ap) as f:\n",
    "                multi_seed_results.setdefault(mode_tag, {})[seed] = json.load(f)\n",
    "        else:\n",
    "            print(f\"  WARNING: No results for seed {seed} {mode_tag}\")\n",
    "\n",
    "# Aggregate and report\n",
    "METRICS = [\n",
    "    'vamp2_score', 'spectral_gap', 'entropy_empirical', 'entropy_total',\n",
    "    'mean_irreversibility', 'detailed_balance_violation',\n",
    "    'fluctuation_theorem_ratio', 'n_complex_modes', 'complex_fraction',\n",
    "    'ktnd_nber_accuracy', 'ktnd_nber_f1',\n",
    "]\n",
    "\n",
    "multi_seed_summary = {}\n",
    "for mode_tag in [\"univariate\", \"multiasset\"]:\n",
    "    if mode_tag not in multi_seed_results:\n",
    "        continue\n",
    "    seed_data = multi_seed_results[mode_tag]\n",
    "    seeds_present = sorted(seed_data.keys())\n",
    "    print(f\"\\n  === {mode_tag.title()}: {len(seeds_present)} seeds ({seeds_present}) ===\")\n",
    "\n",
    "    summary = {'n_seeds': len(seeds_present), 'seeds': seeds_present}\n",
    "    for metric in METRICS:\n",
    "        vals = [seed_data[s].get(metric) for s in seeds_present\n",
    "                if seed_data[s].get(metric) is not None]\n",
    "        if vals:\n",
    "            vals = [float(v) for v in vals]\n",
    "            mean_val = np.mean(vals)\n",
    "            std_val = np.std(vals, ddof=1) if len(vals) > 1 else 0.0\n",
    "            summary[f'{metric}_mean'] = float(mean_val)\n",
    "            summary[f'{metric}_std'] = float(std_val)\n",
    "            print(f\"    {metric:35s}  {mean_val:.4f} +/- {std_val:.4f}  (n={len(vals)})\")\n",
    "\n",
    "    multi_seed_summary[mode_tag] = summary\n",
    "\n",
    "# Save aggregated results\n",
    "ms_path = f\"{RESULTS_DIR}/multi_seed_summary.json\"\n",
    "with open(ms_path, 'w') as f:\n",
    "    json.dump(multi_seed_summary, f, indent=2, default=str)\n",
    "print(f\"\\n  Saved: {ms_path}\")\n",
    "results['multi_seed'] = os.path.exists(ms_path)\n",
    "\n",
    "\n",
    "# ======================================================================\n",
    "# FINAL REPORT\n",
    "# ======================================================================\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"  ALL OUTPUT FILES\")\n",
    "print(f\"{'='*70}\")\n",
    "for dirpath, dirnames, filenames in os.walk(OUTPUT_DIR):\n",
    "    for f in sorted(filenames):\n",
    "        fp = os.path.join(dirpath, f)\n",
    "        sz = os.path.getsize(fp)\n",
    "        rel = os.path.relpath(fp, OUTPUT_DIR)\n",
    "        print(f\"  {sz:>10,} bytes  {rel}\")\n",
    "\n",
    "total_min = (time.time() - pipeline_start) / 60\n",
    "n_ok = sum(v for v in results.values() if isinstance(v, bool) and v)\n",
    "n_total = len(results)\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"  COMPLETE: {n_ok}/{n_total} stages passed ({total_min:.1f} min total)\")\n",
    "print(f\"  Version: v1.5.3\")\n",
    "print(f\"{'='*70}\")\n",
    "for name, ok in results.items():\n",
    "    print(f\"  {'OK' if ok else 'FAIL':6s}  {name}\")\n",
    "\n",
    "# Print single-seed results for BOTH modes\n",
    "for mode_tag, label in [(\"univariate\", \"Univariate (SPY)\"), (\"multiasset\", \"Multiasset (11 ETFs)\")]:\n",
    "    ap = f\"{RESULTS_DIR}/analysis_results_{mode_tag}.json\"\n",
    "    if not os.path.exists(ap):\n",
    "        continue\n",
    "    with open(ap) as f:\n",
    "        r = json.load(f)\n",
    "    print(f\"\\n  === {label} (seed 42) ===\")\n",
    "    print(f\"    VAMP-2 score:         {r.get('vamp2_score', 'N/A')}\")\n",
    "    print(f\"    Spectral gap:         {r.get('spectral_gap', 'N/A')}\")\n",
    "    print(f\"    Entropy (empirical):  {r.get('entropy_empirical', 'N/A')} \"\n",
    "          f\"[{r.get('entropy_ci_lower', '?')}, {r.get('entropy_ci_upper', '?')}] 95% CI\")\n",
    "    print(f\"    Spectral entropy:     {r.get('entropy_total', 'N/A')}\")\n",
    "    print(f\"    Mean irreversibility: {r.get('mean_irreversibility', 'N/A')}\")\n",
    "    print(f\"    Irrev method:         {r.get('irrev_method', 'N/A')}\")\n",
    "    print(f\"    DB violation:         {r.get('detailed_balance_violation', 'N/A')}\")\n",
    "    print(f\"    Complex modes:        {r.get('n_complex_modes', 'N/A')}/{r.get('n_modes', 'N/A')}\")\n",
    "    print(f\"    FT ratio:             {r.get('fluctuation_theorem_ratio', 'N/A')}\")\n",
    "\n",
    "    ktnd_acc = r.get('ktnd_nber_accuracy')\n",
    "    if ktnd_acc is not None:\n",
    "        print(f\"    KTND NBER accuracy:   {ktnd_acc:.3f}\")\n",
    "        print(f\"    KTND NBER F1:         {r.get('ktnd_nber_f1', 'N/A'):.3f}\")\n",
    "        print(f\"    KTND naive accuracy:  {r.get('ktnd_naive_accuracy', 'N/A'):.3f}\")\n",
    "        print(f\"    Mean regime duration: {r.get('ktnd_mean_regime_duration', 'N/A'):.1f} days\")\n",
    "\n",
    "# Print multi-seed aggregated results\n",
    "ms_path = f\"{RESULTS_DIR}/multi_seed_summary.json\"\n",
    "if os.path.exists(ms_path):\n",
    "    with open(ms_path) as f:\n",
    "        ms = json.load(f)\n",
    "    print(f\"\\n  === MULTI-SEED SUMMARY (mean +/- std) ===\")\n",
    "    for mode_tag in [\"univariate\", \"multiasset\"]:\n",
    "        if mode_tag not in ms:\n",
    "            continue\n",
    "        s = ms[mode_tag]\n",
    "        label = \"Univariate (SPY)\" if mode_tag == \"univariate\" else \"Multiasset (11 ETFs)\"\n",
    "        print(f\"\\n  {label} ({s.get('n_seeds', '?')} seeds):\")\n",
    "        for metric in METRICS:\n",
    "            mk, sk = f'{metric}_mean', f'{metric}_std'\n",
    "            if mk in s:\n",
    "                print(f\"    {metric:35s}  {s[mk]:.4f} +/- {s[sk]:.4f}\")\n",
    "\n",
    "stat_path = f\"{RESULTS_DIR}/statistical_tests.json\"\n",
    "if os.path.exists(stat_path):\n",
    "    with open(stat_path) as f:\n",
    "        st = json.load(f)\n",
    "    print(f\"\\n  === Statistical Tests ===\")\n",
    "    for k, v in st.items():\n",
    "        if isinstance(v, dict):\n",
    "            if v.get('skipped'):\n",
    "                print(f\"    {k}: SKIPPED ({v.get('reason', '')})\")\n",
    "            else:\n",
    "                pval = v.get('p_value', v.get('pvalue', None))\n",
    "                if pval is not None:\n",
    "                    print(f\"    {k}: p={pval:.4f}\")\n",
    "        elif isinstance(v, (int, float)):\n",
    "            print(f\"    {k}: {v}\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"  DONE. Total wall time: {total_min:.1f} min\")\n",
    "print(f\"  Next: Cell 3 (ablations, optional) -> Cell 4 (view figures) -> Cell 5 (download)\")\n",
    "print(f\"{'='*70}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "#@title 3. Ablations + Brownian gyrator (~6 hours, resume-safe, optional)\n",
    "\n",
    "import subprocess, time, json, os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "REPO_DIR = \"/content/ktnd_finance\"\n",
    "OUTPUT_DIR = \"/content/ktnd_finance/outputs\"\n",
    "RESULTS_DIR = \"/content/ktnd_finance/outputs/results\"\n",
    "N_ABLATION_SEEDS = 10\n",
    "\n",
    "os.chdir(REPO_DIR)\n",
    "python = sys.executable\n",
    "\n",
    "def run_streaming(name, cmd, check_files=None):\n",
    "    \"\"\"Run a stage with LIVE output streaming.\"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"  STAGE: {name}\")\n",
    "    print(f\"  CMD: {cmd}\")\n",
    "    print(f\"{'='*70}\", flush=True)\n",
    "    t0 = time.time()\n",
    "    proc = subprocess.Popen(\n",
    "        cmd, shell=True, cwd=REPO_DIR,\n",
    "        stdout=subprocess.PIPE, stderr=subprocess.STDOUT,\n",
    "        text=True, bufsize=1,\n",
    "    )\n",
    "    for line in proc.stdout:\n",
    "        print(f\"  {line}\", end=\"\", flush=True)\n",
    "    proc.wait()\n",
    "    elapsed = time.time() - t0\n",
    "    if proc.returncode != 0:\n",
    "        print(f\"  >> {name}: FAILED (exit code {proc.returncode}, {elapsed/60:.1f} min)\")\n",
    "        return False\n",
    "    if check_files:\n",
    "        missing = [f for f in check_files if not os.path.exists(f)]\n",
    "        if missing:\n",
    "            for f in missing:\n",
    "                print(f\"    MISSING: {f}\")\n",
    "            print(f\"  >> {name}: INCOMPLETE ({elapsed/60:.1f} min)\")\n",
    "            return False\n",
    "        for f in check_files:\n",
    "            sz = os.path.getsize(f)\n",
    "            print(f\"  OK: {os.path.basename(f)} ({sz:,} bytes)\")\n",
    "    print(f\"  >> {name}: OK ({elapsed/60:.1f} min)\")\n",
    "    return True\n",
    "\n",
    "def run(name, cmd, check_files=None):\n",
    "    \"\"\"Run a stage, print output, verify files.\"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"  STAGE: {name}\")\n",
    "    print(f\"  CMD: {cmd}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    t0 = time.time()\n",
    "    result = subprocess.run(cmd, shell=True, cwd=REPO_DIR, capture_output=True, text=True)\n",
    "    elapsed = time.time() - t0\n",
    "    if result.stdout:\n",
    "        for line in result.stdout.strip().split('\\n'):\n",
    "            print(f\"  {line}\")\n",
    "    if result.returncode != 0:\n",
    "        if result.stderr:\n",
    "            for line in result.stderr.strip().split('\\n')[-20:]:\n",
    "                print(f\"  ! {line}\")\n",
    "        print(f\"  >> {name}: FAILED ({elapsed/60:.1f} min)\")\n",
    "        return False\n",
    "    if check_files:\n",
    "        missing = [f for f in check_files if not os.path.exists(f)]\n",
    "        if missing:\n",
    "            for f in missing:\n",
    "                print(f\"    MISSING: {f}\")\n",
    "            return False\n",
    "    print(f\"  >> {name}: OK ({elapsed/60:.1f} min)\")\n",
    "    return True\n",
    "\n",
    "t_start = time.time()\n",
    "results = {}\n",
    "\n",
    "# ======================================================================\n",
    "# PART 1: ABLATION STUDY (10 seeds x ~32 variants, ~6 hours)\n",
    "# Resume-safe: saves after each variant. Re-run to pick up where it left off.\n",
    "# ======================================================================\n",
    "print(f\"\\n{'#'*70}\")\n",
    "print(f\"#  ABLATION STUDY ({N_ABLATION_SEEDS} seeds x ~32 variants)\")\n",
    "print(f\"#  Resume-safe: skips completed variants\")\n",
    "print(f\"{'#'*70}\")\n",
    "\n",
    "results['ablations'] = run_streaming(f'Ablations ({N_ABLATION_SEEDS} seeds)',\n",
    "    f'{python} -u experiments/run_ablations.py --config config/default.yaml'\n",
    "    f' --n-seeds {N_ABLATION_SEEDS} --n-jobs 1'\n",
    "    f' --output-dir {RESULTS_DIR}',\n",
    "    check_files=[f'{RESULTS_DIR}/ablation_summary.csv'])\n",
    "\n",
    "summary_path = f\"{RESULTS_DIR}/ablation_summary.csv\"\n",
    "if os.path.exists(summary_path):\n",
    "    abl_df = pd.read_csv(summary_path)\n",
    "    print(f\"\\n  {len(abl_df)} ablation variants ({N_ABLATION_SEEDS} seeds each):\")\n",
    "    cols = ['name', 'n_valid', 'vamp2_mean', 'vamp2_std',\n",
    "            'spectral_gap_mean', 'spectral_gap_std',\n",
    "            'entropy_total_mean', 'entropy_total_std']\n",
    "    cols = [c for c in cols if c in abl_df.columns]\n",
    "    print(abl_df[cols].to_string(index=False))\n",
    "\n",
    "    if 'vamp2_mean' in abl_df.columns:\n",
    "        baseline = abl_df[abl_df['name'] == 'baseline']\n",
    "        if len(baseline) > 0:\n",
    "            bl_vamp2 = baseline['vamp2_mean'].values[0]\n",
    "            print(f\"\\n  Baseline VAMP-2: {bl_vamp2:.4f}\")\n",
    "            diff = abl_df.copy()\n",
    "            diff['vamp2_delta'] = ((diff['vamp2_mean'] - bl_vamp2) / abs(bl_vamp2) * 100)\n",
    "            notable = diff[abs(diff['vamp2_delta']) > 5].sort_values('vamp2_delta')\n",
    "            if len(notable) > 0:\n",
    "                print(f\"\\n  Variants with >5% VAMP-2 change from baseline:\")\n",
    "                for _, row in notable.iterrows():\n",
    "                    print(f\"    {row['name']:40s}  {row['vamp2_delta']:+.1f}%\")\n",
    "\n",
    "# ======================================================================\n",
    "# PART 2: BROWNIAN GYRATOR BENCHMARK (~5 min)\n",
    "# ======================================================================\n",
    "print(f\"\\n{'#'*70}\")\n",
    "print(f\"#  BROWNIAN GYRATOR -- analytical EP benchmark\")\n",
    "print(f\"#  2D coupled OU, T1!=T2 breaks detailed balance\")\n",
    "print(f\"{'#'*70}\")\n",
    "\n",
    "from scipy.linalg import solve_continuous_lyapunov\n",
    "\n",
    "def analytical_ep(T1, T2, k=1.0, kappa=0.5):\n",
    "    A = np.array([[k, -kappa], [-kappa, k]])\n",
    "    D = np.array([[T1, 0.0], [0.0, T2]])\n",
    "    Sigma = solve_continuous_lyapunov(A, 2.0 * D)\n",
    "    Q = A - D @ np.linalg.inv(Sigma)\n",
    "    D_inv = np.diag([1.0/T1, 1.0/T2])\n",
    "    return np.trace(Q @ Sigma @ Q.T @ D_inv)\n",
    "\n",
    "print(\"\\n  Analytical EP rates:\")\n",
    "for T2 in [1.0, 1.5, 3.0, 5.0]:\n",
    "    ep = analytical_ep(1.0, T2)\n",
    "    print(f\"    T1=1.0, T2={T2:.1f}:  EP = {ep:.6f}  {'(equilibrium)' if T2 == 1.0 else ''}\")\n",
    "\n",
    "results['gyrator'] = run('Brownian gyrator tests',\n",
    "    f'{python} -m pytest tests/test_synthetic.py::TestBrownianGyrator -v')\n",
    "\n",
    "# ======================================================================\n",
    "# SUMMARY\n",
    "# ======================================================================\n",
    "total_min = (time.time() - t_start) / 60\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"  ABLATIONS + GYRATOR COMPLETE ({total_min:.1f} min)\")\n",
    "print(f\"{'='*70}\")\n",
    "for name, ok in results.items():\n",
    "    print(f\"  {'OK' if ok else 'FAIL':6s}  {name}\")\n",
    "print(f\"\\n  Next: Cell 4 (view figures) -> Cell 5 (download)\")\n",
    "print(f\"{'='*70}\")\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 4. View figures (run after Cell 2 finishes)\n",
    "\n",
    "import glob, os\n",
    "from IPython.display import Image, display\n",
    "\n",
    "FIGURES_DIR = \"/content/ktnd_finance/outputs/figures\"\n",
    "\n",
    "pngs = sorted(glob.glob(f\"{FIGURES_DIR}/*.png\"))\n",
    "sup_dir = os.path.join(FIGURES_DIR, \"supplemental\")\n",
    "if os.path.exists(sup_dir):\n",
    "    pngs += sorted(glob.glob(f\"{sup_dir}/*.png\"))\n",
    "\n",
    "if pngs:\n",
    "    print(f\"Found {len(pngs)} figures:\\n\")\n",
    "    for p in pngs:\n",
    "        print(f\"--- {os.path.basename(p)} ---\")\n",
    "        display(Image(filename=p, width=800))\n",
    "        print()\n",
    "else:\n",
    "    print(\"No figures found. Make sure Cell 2 has finished running first.\")\n",
    "    print(f\"Checked: {FIGURES_DIR}\")\n",
    "    results_dir = \"/content/ktnd_finance/outputs/results\"\n",
    "    if os.path.exists(results_dir):\n",
    "        files = os.listdir(results_dir)\n",
    "        print(f\"Result files available ({len(files)}): {files}\")\n",
    "    else:\n",
    "        print(\"No results directory found - Cell 2 needs to run first.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 5. Download all results as zip\n",
    "\n",
    "!cd /content/ktnd_finance && zip -rq /content/ktnd_results.zip outputs/\n",
    "from google.colab import files\n",
    "files.download('/content/ktnd_results.zip')\n",
    "print(\"Download started.\")"
   ]
  }
 ]
}