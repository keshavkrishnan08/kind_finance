{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# KTND-Finance: Full Experiment Pipeline (v1.5.0)\n\n**IMPORTANT: Re-run required after v1.5.0 fixes.**\n\n### What changed (v1.5.0):\n- **Multi-seed error bars** — 5 seeds (42, 0-3) for main results with mean +/- std aggregation\n- **GARCH(1,1) baseline** — standard econophysics volatility regime detector\n- **Learning rate ablation** — sweep over [3e-4, 1e-3, 3e-3]\n- **Granger date alignment fix** — spectral gap vs VIX now properly date-indexed\n- **VAMP-2 score saved to JSON** — enables multi-seed aggregation\n- **Model improvements** — beta_orth 1.0->0.01, n_modes 10->5 (univariate), permutation n_segments 5->20\n- **Config loading fix** — default.yaml now always loaded for loss weights\n\n### How to run:\n1. **Cell 1** (Setup) — Install deps + clone repo (~2 min)\n2. **Cell 2** (Run Everything) — Full pipeline + multi-seed + ablations + Brownian gyrator (~7-10 hours total, walk away)\n3. **Cell 3** (View) — Display all figures\n4. **Cell 4** (Download) — Zip all results\n\nSet runtime to **GPU (T4)**: Runtime -> Change runtime type -> T4 GPU -> **Run all** -> walk away."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 1. Setup (install + clone + verify) - ~2 min\n",
    "\n",
    "# Install missing dependencies (torch/numpy/pandas/scipy/sklearn/matplotlib are pre-installed)\n",
    "!pip install -q yfinance>=1.0.0 hmmlearn>=0.3.0 statsmodels>=0.14.0 arch>=6.0.0 pyyaml>=6.0\n",
    "\n",
    "# Clone repo\n",
    "import os, sys\n",
    "REPO_URL = \"https://github.com/keshavkrishnan08/kind_finance.git\"\n",
    "REPO_DIR = \"/content/ktnd_finance\"\n",
    "\n",
    "if os.path.exists(REPO_DIR):\n",
    "    !cd {REPO_DIR} && git pull\n",
    "else:\n",
    "    !git clone {REPO_URL} {REPO_DIR}\n",
    "\n",
    "os.chdir(REPO_DIR)\n",
    "sys.path.insert(0, REPO_DIR)\n",
    "\n",
    "# Verify\n",
    "import torch, numpy as np\n",
    "from src.model.vampnet import NonEquilibriumVAMPNet\n",
    "print(f\"Python {sys.version.split()[0]} | PyTorch {torch.__version__} | \"\n",
    "      f\"CUDA: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}\")\n",
    "print(\"Setup complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#@title 2. Run EVERYTHING — pipeline + ablations + gyrator (~5-7 hours, walk away)\n\nimport subprocess, time, json, os, sys, glob\n\n# ==========================================================================\n# PATHS\n# ==========================================================================\nREPO_DIR = \"/content/ktnd_finance\"\nOUTPUT_DIR = \"/content/ktnd_finance/outputs\"\nRESULTS_DIR = \"/content/ktnd_finance/outputs/results\"\nMODELS_DIR = \"/content/ktnd_finance/outputs/models\"\nFIGURES_DIR = \"/content/ktnd_finance/outputs/figures\"\nDATA_DIR = \"/content/ktnd_finance/data\"\nN_ABLATION_SEEDS = 10  # PRE requires >=10 for reliable std errors\n\nfor d in [OUTPUT_DIR, RESULTS_DIR, MODELS_DIR, FIGURES_DIR]:\n    os.makedirs(d, exist_ok=True)\n\nos.chdir(REPO_DIR)\npython = sys.executable\n\nprint(f\"Python: {python}\")\nprint(f\"CWD: {os.getcwd()}\")\nprint(f\"Repo dir exists: {os.path.exists(REPO_DIR)}\")\nprint(f\"src/ exists: {os.path.isdir(os.path.join(REPO_DIR, 'src'))}\")\nprint(f\"experiments/ exists: {os.path.isdir(os.path.join(REPO_DIR, 'experiments'))}\")\nprint(f\"config/ exists: {os.path.isdir(os.path.join(REPO_DIR, 'config'))}\")\n\ndef run(name, cmd, check_files=None):\n    \"\"\"Run a stage, print output, verify files.\"\"\"\n    print(f\"\\n{'='*70}\")\n    print(f\"  STAGE: {name}\")\n    print(f\"  CMD: {cmd}\")\n    print(f\"{'='*70}\")\n    t0 = time.time()\n    result = subprocess.run(cmd, shell=True, cwd=REPO_DIR,\n                            capture_output=True, text=True)\n    elapsed = time.time() - t0\n\n    if result.stdout:\n        for line in result.stdout.strip().split('\\n'):\n            print(f\"  {line}\")\n\n    if result.returncode != 0:\n        print(f\"\\n  === STDERR ===\")\n        if result.stderr:\n            for line in result.stderr.strip().split('\\n'):\n                print(f\"  ! {line}\")\n        print(f\"  >> {name}: FAILED (exit code {result.returncode}, {elapsed/60:.1f} min)\")\n        return False\n\n    if result.stderr:\n        stderr_lines = result.stderr.strip().split('\\n')\n        error_lines = [l for l in stderr_lines if 'Error' in l or 'Exception' in l or 'Traceback' in l]\n        if error_lines:\n            print(f\"  === STDERR (errors) ===\")\n            for line in error_lines:\n                print(f\"  ! {line}\")\n\n    if check_files:\n        missing = [f for f in check_files if not os.path.exists(f)]\n        if missing:\n            print(f\"  WARNING: Missing expected output files:\")\n            for f in missing:\n                print(f\"    MISSING: {f}\")\n            if result.stderr:\n                for line in result.stderr.strip().split('\\n')[-30:]:\n                    print(f\"  ! {line}\")\n            print(f\"  >> {name}: INCOMPLETE ({elapsed/60:.1f} min)\")\n            return False\n        for f in check_files:\n            sz = os.path.getsize(f)\n            print(f\"  OK: {os.path.basename(f)} ({sz:,} bytes)\")\n\n    print(f\"  >> {name}: OK ({elapsed/60:.1f} min)\")\n    return True\n\ndef run_streaming(name, cmd, check_files=None):\n    \"\"\"Run a stage with LIVE output streaming (for long-running tasks).\"\"\"\n    print(f\"\\n{'='*70}\")\n    print(f\"  STAGE: {name}\")\n    print(f\"  CMD: {cmd}\")\n    print(f\"{'='*70}\", flush=True)\n    t0 = time.time()\n    proc = subprocess.Popen(\n        cmd, shell=True, cwd=REPO_DIR,\n        stdout=subprocess.PIPE, stderr=subprocess.STDOUT,\n        text=True, bufsize=1,\n    )\n    for line in proc.stdout:\n        print(f\"  {line}\", end=\"\", flush=True)\n    proc.wait()\n    elapsed = time.time() - t0\n\n    if proc.returncode != 0:\n        print(f\"  >> {name}: FAILED (exit code {proc.returncode}, {elapsed/60:.1f} min)\")\n        return False\n\n    if check_files:\n        missing = [f for f in check_files if not os.path.exists(f)]\n        if missing:\n            print(f\"  WARNING: Missing expected output files:\")\n            for f in missing:\n                print(f\"    MISSING: {f}\")\n            print(f\"  >> {name}: INCOMPLETE ({elapsed/60:.1f} min)\")\n            return False\n        for f in check_files:\n            sz = os.path.getsize(f)\n            print(f\"  OK: {os.path.basename(f)} ({sz:,} bytes)\")\n\n    print(f\"  >> {name}: OK ({elapsed/60:.1f} min)\")\n    return True\n\npipeline_start = time.time()\nresults = {}\n\n# ======================================================================\n# PART A: FULL PIPELINE (~2-3 hours)\n# ======================================================================\nprint(f\"\\n{'#'*70}\")\nprint(f\"#  PART A: FULL PIPELINE\")\nprint(f\"#  Order: tests -> download -> train(uni+multi) -> baselines ->\")\nprint(f\"#         rolling -> robustness(needs rolling output) -> figures\")\nprint(f\"{'#'*70}\")\n\n# --- Stage 1: Quick tests ---\nresults['tests'] = run('Quick tests',\n    f'{python} -m pytest tests/ -q --tb=short -k \"not test_synthetic\"')\n\n# --- Stage 2: Download data ---\nresults['download'] = run('Download data',\n    f'{python} {REPO_DIR}/data/download.py --mode all',\n    check_files=[f'{DATA_DIR}/prices.csv', f'{DATA_DIR}/vix.csv'])\n\n# --- Stage 3: Train univariate ---\n# NOTE: --config default.yaml ensures all loss weights/training params are loaded.\n# Mode-specific overrides (n_modes=5, hidden_dims, batch_size) merge from univariate.yaml.\nresults['train_uni'] = run('Train univariate (SPY)',\n    f'{python} {REPO_DIR}/experiments/run_main.py'\n    f' --config config/default.yaml --mode univariate --seed 42'\n    f' --output-dir {OUTPUT_DIR}',\n    check_files=[\n        f'{RESULTS_DIR}/analysis_results.json',\n        f'{RESULTS_DIR}/eigenvalues.csv',\n        f'{RESULTS_DIR}/entropy_decomposition.csv',\n        f'{RESULTS_DIR}/irreversibility_field.npy',\n        f'{MODELS_DIR}/vampnet_univariate.pt',\n    ])\n\n# --- Stage 4: Train multiasset ---\nresults['train_multi'] = run('Train multiasset (11 ETFs)',\n    f'{python} {REPO_DIR}/experiments/run_main.py'\n    f' --config config/default.yaml --mode multiasset --seed 42'\n    f' --output-dir {OUTPUT_DIR}',\n    check_files=[f'{RESULTS_DIR}/analysis_results_multiasset.json',\n                 f'{MODELS_DIR}/vampnet_multiasset.pt'])\n\n# --- Stage 5: Baselines ---\nresults['baselines'] = run('Baselines',\n    f'{python} {REPO_DIR}/experiments/run_baselines.py'\n    f' --config config/default.yaml --output-dir {RESULTS_DIR}',\n    check_files=[f'{RESULTS_DIR}/baseline_comparison.csv'])\n\n# --- Stage 6: Rolling (BEFORE robustness -- Granger needs spectral_gap_timeseries.csv) ---\nresults['rolling'] = run('Rolling spectral analysis',\n    f'{python} {REPO_DIR}/experiments/run_rolling.py'\n    f' --config config/default.yaml --mode univariate'\n    f' --checkpoint {MODELS_DIR}/vampnet_univariate.pt'\n    f' --output-dir {RESULTS_DIR}',\n    check_files=[f'{RESULTS_DIR}/spectral_gap_timeseries.csv'])\n\n# --- Stage 7: Robustness (AFTER rolling -- Granger needs spectral_gap_timeseries.csv) ---\nresults['robustness'] = run('Robustness tests',\n    f'{python} {REPO_DIR}/experiments/run_robustness.py'\n    f' --config config/default.yaml --mode univariate'\n    f' --checkpoint {MODELS_DIR}/vampnet_univariate.pt'\n    f' --output-dir {RESULTS_DIR}',\n    check_files=[f'{RESULTS_DIR}/statistical_tests.json'])\n\n# --- Stage 8: Figures (script) ---\nresults['figures'] = run('Generate figures (script)',\n    f'{python} {REPO_DIR}/experiments/run_figures.py'\n    f' --results-dir {RESULTS_DIR} --figures-dir {FIGURES_DIR}')\n\n# --- Stage 9: Figures (inline fallback) ---\nprint(f\"\\n{'='*70}\")\nprint(f\"  GENERATING FIGURES INLINE (FALLBACK)\")\nprint(f\"{'='*70}\")\n\nimport matplotlib\nmatplotlib.use(\"Agg\")\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\nn_figs = 0\n\nfor mode_tag, label in [(\"univariate\", \"Univariate (SPY)\"), (\"multiasset\", \"Multiasset\")]:\n    ap = f\"{RESULTS_DIR}/analysis_results_{mode_tag}.json\"\n    if not os.path.exists(ap):\n        continue\n    with open(ap) as f:\n        ar = json.load(f)\n\n    er, ei = ar.get(\"eigenvalues_real\"), ar.get(\"eigenvalues_imag\")\n    if er and ei:\n        er, ei = np.array(er), np.array(ei)\n        mags = np.sqrt(er**2 + ei**2)\n        fig, ax = plt.subplots(figsize=(7,7))\n        th = np.linspace(0, 2*np.pi, 300)\n        ax.plot(np.cos(th), np.sin(th), \"k--\", lw=0.8, alpha=0.5)\n        sc = ax.scatter(er, ei, c=mags, cmap=\"viridis\", edgecolors=\"k\", linewidths=0.4, s=80, zorder=3)\n        plt.colorbar(sc, ax=ax, label=\"|$\\\\lambda$|\")\n        for i, idx in enumerate(np.argsort(-mags)[:5]):\n            ax.annotate(f\"$\\\\lambda_{i}$\", (er[idx], ei[idx]), textcoords=\"offset points\", xytext=(8,8), fontsize=9)\n        ax.set_xlabel(\"Re($\\\\lambda$)\"); ax.set_ylabel(\"Im($\\\\lambda$)\")\n        ax.set_title(f\"Koopman Eigenvalue Spectrum -- {label}\"); ax.set_aspect(\"equal\"); ax.grid(True, alpha=0.3)\n        fig.savefig(f\"{FIGURES_DIR}/fig1_eigenvalue_spectrum_{mode_tag}.png\", dpi=300, bbox_inches=\"tight\"); plt.close(fig); n_figs += 1\n\nfor csv_name, title, ycol in [\n    (\"eigenvalues.csv\", \"Eigenvalue Magnitudes\", \"magnitude\"),\n    (\"entropy_decomposition.csv\", \"Entropy Decomposition\", \"entropy_production\"),\n]:\n    p = f\"{RESULTS_DIR}/{csv_name}\"\n    if os.path.exists(p):\n        df = pd.read_csv(p)\n        if ycol in df.columns:\n            fig, ax = plt.subplots(figsize=(8,5))\n            ax.bar(df[\"mode\"], df[ycol], color=\"coral\" if \"entropy\" in csv_name else \"steelblue\", edgecolor=\"black\", lw=0.3)\n            ax.set_xlabel(\"Mode\"); ax.set_ylabel(ycol); ax.set_title(title); ax.grid(True, alpha=0.3, axis=\"y\")\n            fig.savefig(f\"{FIGURES_DIR}/fig_{csv_name.replace('.csv','')}.png\", dpi=300, bbox_inches=\"tight\"); plt.close(fig); n_figs += 1\n\nirp = f\"{RESULTS_DIR}/irreversibility_field.npy\"\nif os.path.exists(irp):\n    ir = np.load(irp, allow_pickle=True)\n    fig, ax = plt.subplots(figsize=(14,4))\n    ax.fill_between(range(len(ir)), ir, alpha=0.4, color=\"darkorange\"); ax.plot(ir, lw=0.5, color=\"darkorange\")\n    ax.set_xlabel(\"Time\"); ax.set_ylabel(\"$I(x)$\"); ax.set_title(\"Irreversibility Field\"); ax.grid(True, alpha=0.3)\n    fig.savefig(f\"{FIGURES_DIR}/fig_irreversibility_field.png\", dpi=300, bbox_inches=\"tight\"); plt.close(fig); n_figs += 1\n\nrcp = f\"{RESULTS_DIR}/spectral_gap_timeseries.csv\"\nif os.path.exists(rcp):\n    rdf = pd.read_csv(rcp)\n    if \"spectral_gap\" in rdf.columns:\n        fig, ax = plt.subplots(figsize=(14,5))\n        x = pd.to_datetime(rdf[\"center_date\"]) if \"center_date\" in rdf.columns else range(len(rdf))\n        ax.plot(x, rdf[\"spectral_gap\"], color=\"steelblue\", lw=1.0)\n        ax.set_xlabel(\"Date\"); ax.set_ylabel(\"Spectral Gap\"); ax.set_title(\"Rolling Spectral Gap\"); ax.grid(True, alpha=0.3)\n        fig.savefig(f\"{FIGURES_DIR}/fig_spectral_gap.png\", dpi=300, bbox_inches=\"tight\"); plt.close(fig); n_figs += 1\n\nbcp = f\"{RESULTS_DIR}/baseline_comparison.csv\"\nif os.path.exists(bcp):\n    bdf = pd.read_csv(bcp)\n    ms = [m for m in [\"nber_accuracy\",\"nber_f1\",\"nber_precision\",\"nber_recall\"] if m in bdf.columns]\n    if ms and \"method\" in bdf.columns:\n        fig, ax = plt.subplots(figsize=(10,6))\n        x = np.arange(len(bdf)); w = 0.8/len(ms)\n        for i, m in enumerate(ms):\n            ax.bar(x+i*w, bdf[m].astype(float), w, label=m.replace(\"nber_\",\"\").title(),\n                   color=[\"steelblue\",\"coral\",\"seagreen\",\"orchid\"][i%4], edgecolor=\"black\", lw=0.3)\n        ax.set_xticks(x+w*(len(ms)-1)/2); ax.set_xticklabels(bdf[\"method\"], rotation=15, ha=\"right\")\n        ax.set_ylabel(\"Score\"); ax.set_title(\"Baseline Comparison\"); ax.legend(); ax.set_ylim(0,1.05)\n        fig.savefig(f\"{FIGURES_DIR}/fig_baseline_comparison.png\", dpi=300, bbox_inches=\"tight\"); plt.close(fig); n_figs += 1\n\nprint(f\"  Generated {n_figs} figures inline\")\n\n# ======================================================================\n# PART A2: MULTI-SEED ERROR BARS (5 seeds total, ~1.5 hours)\n# PRE requires error bars on main results. Run 4 additional seeds\n# for training + analysis only (baselines/rolling/figures use seed 42).\n# ======================================================================\nN_MAIN_SEEDS = 5\nEXTRA_SEEDS = [0, 1, 2, 3]  # + seed 42 from above = 5 total\n\nprint(f\"\\n{'#'*70}\")\nprint(f\"#  PART A2: MULTI-SEED ERROR BARS ({N_MAIN_SEEDS} seeds)\")\nprint(f\"#  Running {len(EXTRA_SEEDS)} additional seeds + seed 42 from above\")\nprint(f\"#  Only re-runs training + analysis (not baselines/rolling/figures)\")\nprint(f\"{'#'*70}\")\n\nmulti_seed_results = {}\n\n# Collect seed=42 results from the primary run\nfor mode_tag in [\"univariate\", \"multiasset\"]:\n    ap = f\"{RESULTS_DIR}/analysis_results_{mode_tag}.json\"\n    if os.path.exists(ap):\n        with open(ap) as f:\n            multi_seed_results.setdefault(mode_tag, {})[42] = json.load(f)\n\n# Run extra seeds\nfor seed in EXTRA_SEEDS:\n    seed_dir = f\"{OUTPUT_DIR}/seed_{seed}\"\n    seed_results = f\"{seed_dir}/results\"\n    seed_models = f\"{seed_dir}/models\"\n    os.makedirs(seed_results, exist_ok=True)\n    os.makedirs(seed_models, exist_ok=True)\n\n    for mode_tag in [\"univariate\", \"multiasset\"]:\n        # Check if already completed (resume-safe)\n        seed_ap = f\"{seed_results}/analysis_results_{mode_tag}.json\"\n        if os.path.exists(seed_ap):\n            print(f\"\\n  --- Seed {seed}, mode={mode_tag}: ALREADY DONE (resuming) ---\")\n            with open(seed_ap) as f:\n                multi_seed_results.setdefault(mode_tag, {})[seed] = json.load(f)\n            continue\n\n        print(f\"\\n  --- Seed {seed}, mode={mode_tag} ---\", flush=True)\n        ok = run(f'Seed {seed} {mode_tag}',\n            f'{python} {REPO_DIR}/experiments/run_main.py'\n            f' --config config/default.yaml --mode {mode_tag} --seed {seed}'\n            f' --output-dir {seed_dir}')\n\n        if os.path.exists(seed_ap):\n            with open(seed_ap) as f:\n                multi_seed_results.setdefault(mode_tag, {})[seed] = json.load(f)\n        else:\n            print(f\"  WARNING: No results for seed {seed} {mode_tag}\")\n\n# Aggregate and report\nMETRICS = [\n    'vamp2_score', 'spectral_gap', 'entropy_empirical', 'entropy_total',\n    'mean_irreversibility', 'detailed_balance_violation',\n    'fluctuation_theorem_ratio', 'n_complex_modes', 'complex_fraction',\n    'ktnd_nber_accuracy', 'ktnd_nber_f1',\n]\n\nmulti_seed_summary = {}\nfor mode_tag in [\"univariate\", \"multiasset\"]:\n    if mode_tag not in multi_seed_results:\n        continue\n    seed_data = multi_seed_results[mode_tag]\n    seeds_present = sorted(seed_data.keys())\n    print(f\"\\n  === {mode_tag.title()}: {len(seeds_present)} seeds ({seeds_present}) ===\")\n\n    summary = {'n_seeds': len(seeds_present), 'seeds': seeds_present}\n    for metric in METRICS:\n        vals = [seed_data[s].get(metric) for s in seeds_present\n                if seed_data[s].get(metric) is not None]\n        if vals:\n            vals = [float(v) for v in vals]\n            mean_val = np.mean(vals)\n            std_val = np.std(vals, ddof=1) if len(vals) > 1 else 0.0\n            summary[f'{metric}_mean'] = float(mean_val)\n            summary[f'{metric}_std'] = float(std_val)\n            print(f\"    {metric:35s}  {mean_val:.4f} +/- {std_val:.4f}  (n={len(vals)})\")\n\n    multi_seed_summary[mode_tag] = summary\n\n# Save aggregated results\nms_path = f\"{RESULTS_DIR}/multi_seed_summary.json\"\nwith open(ms_path, 'w') as f:\n    json.dump(multi_seed_summary, f, indent=2, default=str)\nprint(f\"\\n  Saved: {ms_path}\")\nresults['multi_seed'] = os.path.exists(ms_path)\n\n# ======================================================================\n# PART B: ABLATION STUDY (10 seeds, ~6-10 hours)\n# Uses STREAMING output so you can see progress live.\n# Saves incrementally -- if Colab disconnects, re-run and it resumes.\n# ======================================================================\nprint(f\"\\n{'#'*70}\")\nprint(f\"#  PART B: ABLATION STUDY ({N_ABLATION_SEEDS} seeds x ~32 variants)\")\nprint(f\"#  v1.4.0: shared_weights/no_entropy/no_spectral now correctly applied\")\nprint(f\"#  Output streams live. Saves after each variant (resume-safe).\")\nprint(f\"{'#'*70}\")\n\n# Use run_streaming for ablations -- output appears line-by-line\nresults['ablations'] = run_streaming(f'Ablations ({N_ABLATION_SEEDS} seeds)',\n    f'{python} -u experiments/run_ablations.py --config config/default.yaml'\n    f' --n-seeds {N_ABLATION_SEEDS} --n-jobs 1'\n    f' --output-dir {RESULTS_DIR}',\n    check_files=[f'{RESULTS_DIR}/ablation_summary.csv'])\n\nsummary_path = f\"{RESULTS_DIR}/ablation_summary.csv\"\nif os.path.exists(summary_path):\n    abl_df = pd.read_csv(summary_path)\n    print(f\"\\n  {len(abl_df)} ablation variants ({N_ABLATION_SEEDS} seeds each):\")\n    cols = ['name', 'n_valid', 'vamp2_mean', 'vamp2_std',\n            'spectral_gap_mean', 'spectral_gap_std',\n            'entropy_total_mean', 'entropy_total_std']\n    cols = [c for c in cols if c in abl_df.columns]\n    print(abl_df[cols].to_string(index=False))\n\n    if 'vamp2_mean' in abl_df.columns:\n        baseline = abl_df[abl_df['name'] == 'baseline']\n        if len(baseline) > 0:\n            bl_vamp2 = baseline['vamp2_mean'].values[0]\n            print(f\"\\n  Baseline VAMP-2: {bl_vamp2:.4f}\")\n            diff = abl_df.copy()\n            diff['vamp2_delta'] = ((diff['vamp2_mean'] - bl_vamp2) / abs(bl_vamp2) * 100)\n            notable = diff[abs(diff['vamp2_delta']) > 5].sort_values('vamp2_delta')\n            if len(notable) > 0:\n                print(f\"\\n  Variants with >5% VAMP-2 change from baseline:\")\n                for _, row in notable.iterrows():\n                    print(f\"    {row['name']:40s}  {row['vamp2_delta']:+.1f}%\")\n\n# ======================================================================\n# PART C: BROWNIAN GYRATOR BENCHMARK (~5 min)\n# ======================================================================\nprint(f\"\\n{'#'*70}\")\nprint(f\"#  PART C: BROWNIAN GYRATOR -- analytical EP benchmark\")\nprint(f\"#  2D coupled OU, T1!=T2 breaks detailed balance\")\nprint(f\"#  Exact EP: sigma = Tr[Q Sigma Q^T D^-1]\")\nprint(f\"{'#'*70}\")\n\nfrom scipy.linalg import solve_continuous_lyapunov\n\ndef analytical_ep(T1, T2, k=1.0, kappa=0.5):\n    A = np.array([[k, -kappa], [-kappa, k]])\n    D = np.array([[T1, 0.0], [0.0, T2]])\n    Sigma = solve_continuous_lyapunov(A, 2.0 * D)\n    Q = A - D @ np.linalg.inv(Sigma)\n    D_inv = np.diag([1.0/T1, 1.0/T2])\n    return np.trace(Q @ Sigma @ Q.T @ D_inv)\n\nprint(\"\\n  Analytical EP rates:\")\nfor T2 in [1.0, 1.5, 3.0, 5.0]:\n    ep = analytical_ep(1.0, T2)\n    print(f\"    T1=1.0, T2={T2:.1f}:  EP = {ep:.6f}  {'(equilibrium)' if T2 == 1.0 else ''}\")\n\nresults['gyrator'] = run('Brownian gyrator tests',\n    f'{python} -m pytest tests/test_synthetic.py::TestBrownianGyrator -v')\n\n# ======================================================================\n# FINAL REPORT\n# ======================================================================\n\nprint(f\"\\n{'='*70}\")\nprint(f\"  ALL OUTPUT FILES\")\nprint(f\"{'='*70}\")\nfor dirpath, dirnames, filenames in os.walk(OUTPUT_DIR):\n    for f in sorted(filenames):\n        fp = os.path.join(dirpath, f)\n        sz = os.path.getsize(fp)\n        rel = os.path.relpath(fp, OUTPUT_DIR)\n        print(f\"  {sz:>10,} bytes  {rel}\")\n\ntotal_min = (time.time() - pipeline_start) / 60\nn_ok = sum(v for v in results.values() if isinstance(v, bool) and v)\nn_total = len(results)\n\nprint(f\"\\n{'='*70}\")\nprint(f\"  COMPLETE: {n_ok}/{n_total} stages passed ({total_min:.1f} min total)\")\nprint(f\"  Version: v1.5.0\")\nprint(f\"{'='*70}\")\nfor name, ok in results.items():\n    print(f\"  {'OK' if ok else 'FAIL':6s}  {name}\")\n\n# Print single-seed results for BOTH modes\nfor mode_tag, label in [(\"univariate\", \"Univariate (SPY)\"), (\"multiasset\", \"Multiasset (11 ETFs)\")]:\n    ap = f\"{RESULTS_DIR}/analysis_results_{mode_tag}.json\"\n    if not os.path.exists(ap):\n        continue\n    with open(ap) as f:\n        r = json.load(f)\n    print(f\"\\n  === {label} (seed 42) ===\")\n    print(f\"    VAMP-2 score:         {r.get('vamp2_score', 'N/A')}\")\n    print(f\"    Spectral gap:         {r.get('spectral_gap', 'N/A')}\")\n    print(f\"    Entropy (empirical):  {r.get('entropy_empirical', 'N/A')} \"\n          f\"[{r.get('entropy_ci_lower', '?')}, {r.get('entropy_ci_upper', '?')}] 95% CI\")\n    print(f\"    Spectral entropy:     {r.get('entropy_total', 'N/A')}\")\n    print(f\"    Mean irreversibility: {r.get('mean_irreversibility', 'N/A')}\")\n    print(f\"    Irrev method:         {r.get('irrev_method', 'N/A')}\")\n    print(f\"    DB violation:         {r.get('detailed_balance_violation', 'N/A')}\")\n    print(f\"    Complex modes:        {r.get('n_complex_modes', 'N/A')}/{r.get('n_modes', 'N/A')}\")\n    print(f\"    FT ratio:             {r.get('fluctuation_theorem_ratio', 'N/A')}\")\n\n    ktnd_acc = r.get('ktnd_nber_accuracy')\n    if ktnd_acc is not None:\n        print(f\"    KTND NBER accuracy:   {ktnd_acc:.3f}\")\n        print(f\"    KTND NBER F1:         {r.get('ktnd_nber_f1', 'N/A'):.3f}\")\n        print(f\"    KTND naive accuracy:  {r.get('ktnd_naive_accuracy', 'N/A'):.3f}\")\n        print(f\"    Mean regime duration: {r.get('ktnd_mean_regime_duration', 'N/A'):.1f} days\")\n\n# Print multi-seed aggregated results\nms_path = f\"{RESULTS_DIR}/multi_seed_summary.json\"\nif os.path.exists(ms_path):\n    with open(ms_path) as f:\n        ms = json.load(f)\n    print(f\"\\n  === MULTI-SEED SUMMARY (mean +/- std) ===\")\n    for mode_tag in [\"univariate\", \"multiasset\"]:\n        if mode_tag not in ms:\n            continue\n        s = ms[mode_tag]\n        label = \"Univariate (SPY)\" if mode_tag == \"univariate\" else \"Multiasset (11 ETFs)\"\n        print(f\"\\n  {label} ({s.get('n_seeds', '?')} seeds):\")\n        for metric in METRICS:\n            mk, sk = f'{metric}_mean', f'{metric}_std'\n            if mk in s:\n                print(f\"    {metric:35s}  {s[mk]:.4f} +/- {s[sk]:.4f}\")\n\nstat_path = f\"{RESULTS_DIR}/statistical_tests.json\"\nif os.path.exists(stat_path):\n    with open(stat_path) as f:\n        st = json.load(f)\n    print(f\"\\n  === Statistical Tests ===\")\n    for k, v in st.items():\n        if isinstance(v, dict):\n            if v.get('skipped'):\n                print(f\"    {k}: SKIPPED ({v.get('reason', '')})\")\n            else:\n                pval = v.get('p_value', v.get('pvalue', None))\n                if pval is not None:\n                    print(f\"    {k}: p={pval:.4f}\")\n        elif isinstance(v, (int, float)):\n            print(f\"    {k}: {v}\")\n\nprint(f\"\\n{'='*70}\")\nprint(f\"  DONE. Total wall time: {total_min:.1f} min\")\nprint(f\"  Next: Cell 3 (view figures) -> Cell 4 (download zip)\")\nprint(f\"{'='*70}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#@title 3. View figures (run after Cell 2 finishes)\n\nimport glob, os\nfrom IPython.display import Image, display\n\nFIGURES_DIR = \"/content/ktnd_finance/outputs/figures\"\n\npngs = sorted(glob.glob(f\"{FIGURES_DIR}/*.png\"))\nsup_dir = os.path.join(FIGURES_DIR, \"supplemental\")\nif os.path.exists(sup_dir):\n    pngs += sorted(glob.glob(f\"{sup_dir}/*.png\"))\n\nif pngs:\n    print(f\"Found {len(pngs)} figures:\\n\")\n    for p in pngs:\n        print(f\"--- {os.path.basename(p)} ---\")\n        display(Image(filename=p, width=800))\n        print()\nelse:\n    print(\"No figures found. Make sure Cell 2 has finished running first.\")\n    print(f\"Checked: {FIGURES_DIR}\")\n    results_dir = \"/content/ktnd_finance/outputs/results\"\n    if os.path.exists(results_dir):\n        files = os.listdir(results_dir)\n        print(f\"Result files available ({len(files)}): {files}\")\n    else:\n        print(\"No results directory found - Cell 2 needs to run first.\")\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 4. Download all results as zip\n",
    "\n",
    "!cd /content/ktnd_finance && zip -rq /content/ktnd_results.zip outputs/\n",
    "from google.colab import files\n",
    "files.download('/content/ktnd_results.zip')\n",
    "print(\"Download started.\")"
   ]
  }
 ]
}