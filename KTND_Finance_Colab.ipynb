{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KTND-Finance: Full Experiment Pipeline\n",
    "\n",
    "**Run everything in 2 cells:**\n",
    "1. **Cell 1** (Setup) - Install deps + clone repo (~2 min)\n",
    "2. **Cell 2** (Run All) - Downloads data, trains models, runs baselines/robustness/rolling, generates figures (~2-3 hours)\n",
    "\n",
    "Set runtime to **GPU (T4)** before running: Runtime > Change runtime type > T4 GPU\n",
    "\n",
    "Then hit **Runtime > Run all** and walk away."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 1. Setup (install + clone + verify) - ~2 min\n",
    "\n",
    "# Install missing dependencies (torch/numpy/pandas/scipy/sklearn/matplotlib are pre-installed)\n",
    "!pip install -q yfinance>=1.0.0 hmmlearn>=0.3.0 statsmodels>=0.14.0 arch>=6.0.0 pyyaml>=6.0\n",
    "\n",
    "# Clone repo\n",
    "import os, sys\n",
    "REPO_URL = \"https://github.com/keshavkrishnan08/kind_finance.git\"\n",
    "REPO_DIR = \"/content/ktnd_finance\"\n",
    "\n",
    "if os.path.exists(REPO_DIR):\n",
    "    !cd {REPO_DIR} && git pull\n",
    "else:\n",
    "    !git clone {REPO_URL} {REPO_DIR}\n",
    "\n",
    "os.chdir(REPO_DIR)\n",
    "sys.path.insert(0, REPO_DIR)\n",
    "\n",
    "# Verify\n",
    "import torch, numpy as np\n",
    "from src.model.vampnet import NonEquilibriumVAMPNet\n",
    "print(f\"Python {sys.version.split()[0]} | PyTorch {torch.__version__} | \"\n",
    "      f\"CUDA: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}\")\n",
    "print(\"Setup complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#@title 2. Run ENTIRE experiment pipeline (~2-3 hours) - just run this and walk away\n\nimport subprocess, time, json, os, sys, glob\n\nREPO_DIR = \"/content/ktnd_finance\"\nRESULTS_DIR = os.path.join(REPO_DIR, \"outputs\", \"results\")\nFIGURES_DIR = os.path.join(REPO_DIR, \"outputs\", \"figures\")\nos.makedirs(RESULTS_DIR, exist_ok=True)\nos.makedirs(FIGURES_DIR, exist_ok=True)\nos.chdir(REPO_DIR)\npython = sys.executable\n\ndef run(name, cmd, check_files=None):\n    \"\"\"Run a stage, print status, verify output files exist.\"\"\"\n    print(f\"\\n{'='*70}\")\n    print(f\"  STAGE: {name}\")\n    print(f\"{'='*70}\")\n    t0 = time.time()\n    result = subprocess.run(cmd, shell=True, cwd=REPO_DIR,\n                            capture_output=True, text=True)\n    elapsed = time.time() - t0\n\n    # Print last 20 lines of stdout\n    stdout_lines = (result.stdout or '').strip().split('\\n')\n    for line in stdout_lines[-20:]:\n        print(f\"  {line}\")\n\n    if result.returncode != 0:\n        print(f\"\\n  STDERR:\")\n        stderr_lines = (result.stderr or '').strip().split('\\n')\n        for line in stderr_lines[-30:]:\n            print(f\"  ! {line}\")\n        print(f\"  >> {name}: FAILED (exit code {result.returncode}, {elapsed/60:.1f} min)\")\n        return False\n\n    # Verify expected output files exist\n    if check_files:\n        missing = [f for f in check_files if not os.path.exists(f)]\n        if missing:\n            print(f\"  WARNING: Expected files missing after {name}:\")\n            for f in missing:\n                print(f\"    MISSING: {f}\")\n            # Also print stderr in case of silent errors\n            if result.stderr:\n                print(f\"  STDERR (last 10 lines):\")\n                for line in (result.stderr or '').strip().split('\\n')[-10:]:\n                    print(f\"  ! {line}\")\n            print(f\"  >> {name}: INCOMPLETE ({elapsed/60:.1f} min)\")\n            return False\n        else:\n            for f in check_files:\n                sz = os.path.getsize(f)\n                print(f\"  VERIFIED: {os.path.basename(f)} ({sz:,} bytes)\")\n\n    print(f\"  >> {name}: OK ({elapsed/60:.1f} min)\")\n    return True\n\npipeline_start = time.time()\nresults = {}\n\n# --- Stage 1: Quick tests ---\nresults['tests'] = run('Quick tests',\n    f'{python} -m pytest tests/ -q --tb=short -k \"not test_synthetic\"')\n\n# --- Stage 2: Download data ---\nresults['download'] = run('Download data',\n    f'{python} data/download.py --mode all',\n    check_files=[os.path.join(REPO_DIR, 'data', 'prices.csv')])\n\n# --- Stage 3: Train univariate ---\nresults['train_uni'] = run('Train univariate (SPY)',\n    f'{python} experiments/run_main.py --config config/univariate.yaml --mode univariate --seed 42',\n    check_files=[\n        os.path.join(RESULTS_DIR, 'analysis_results.json'),\n        os.path.join(RESULTS_DIR, 'eigenvalues.csv'),\n        os.path.join(RESULTS_DIR, 'entropy_decomposition.csv'),\n        os.path.join(RESULTS_DIR, 'irreversibility_field.npy'),\n    ])\n\n# --- Stage 4: Train multiasset ---\nresults['train_multi'] = run('Train multiasset (11 ETFs)',\n    f'{python} experiments/run_main.py --config config/multiasset.yaml --mode multiasset --seed 42',\n    check_files=[os.path.join(RESULTS_DIR, 'analysis_results.json')])\n\n# --- Stage 5: Baselines ---\nresults['baselines'] = run('Baselines',\n    f'{python} experiments/run_baselines.py --config config/default.yaml',\n    check_files=[os.path.join(RESULTS_DIR, 'baseline_comparison.csv')])\n\n# --- Stage 6: Robustness ---\nresults['robustness'] = run('Robustness tests',\n    f'{python} experiments/run_robustness.py --config config/default.yaml --mode univariate',\n    check_files=[os.path.join(RESULTS_DIR, 'statistical_tests.json')])\n\n# --- Stage 7: Rolling ---\nresults['rolling'] = run('Rolling spectral analysis',\n    f'{python} experiments/run_rolling.py --config config/default.yaml --mode univariate',\n    check_files=[os.path.join(RESULTS_DIR, 'spectral_gap_timeseries.csv')])\n\n# --- Stage 8: Generate figures via run_figures.py ---\nresults['figures'] = run('Generate figures',\n    f'{python} experiments/run_figures.py --results-dir {RESULTS_DIR} --figures-dir {FIGURES_DIR}')\n\n# --- Stage 9: Generate figures INLINE as fallback ---\nprint(f\"\\n{'='*70}\")\nprint(f\"  GENERATING FIGURES INLINE\")\nprint(f\"{'='*70}\")\n\nimport matplotlib\nmatplotlib.use(\"Agg\")\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\nn_figs = 0\n\n# Fig 1: Eigenvalue spectrum\nanalysis_path = os.path.join(RESULTS_DIR, \"analysis_results.json\")\nif os.path.exists(analysis_path):\n    with open(analysis_path) as f:\n        ar = json.load(f)\n\n    eig_real = ar.get(\"eigenvalues_real\")\n    eig_imag = ar.get(\"eigenvalues_imag\")\n    if eig_real and eig_imag:\n        eig_real, eig_imag = np.array(eig_real), np.array(eig_imag)\n        mags = np.sqrt(eig_real**2 + eig_imag**2)\n        fig, ax = plt.subplots(figsize=(7, 7))\n        theta = np.linspace(0, 2*np.pi, 300)\n        ax.plot(np.cos(theta), np.sin(theta), \"k--\", lw=0.8, alpha=0.5)\n        sc = ax.scatter(eig_real, eig_imag, c=mags, cmap=\"viridis\",\n                        edgecolors=\"k\", linewidths=0.4, s=80, zorder=3)\n        plt.colorbar(sc, ax=ax, label=\"|$\\\\lambda$|\")\n        for i, idx in enumerate(np.argsort(-mags)[:5]):\n            ax.annotate(f\"$\\\\lambda_{i}$\", (eig_real[idx], eig_imag[idx]),\n                        textcoords=\"offset points\", xytext=(8,8), fontsize=9)\n        ax.set_xlabel(\"Re($\\\\lambda$)\"); ax.set_ylabel(\"Im($\\\\lambda$)\")\n        ax.set_title(\"Koopman Eigenvalue Spectrum\"); ax.set_aspect(\"equal\"); ax.grid(True, alpha=0.3)\n        fig.savefig(os.path.join(FIGURES_DIR, \"fig1_eigenvalue_spectrum.png\"), dpi=300, bbox_inches=\"tight\")\n        plt.close(fig); n_figs += 1\n\n    svs = ar.get(\"singular_values\")\n    if svs:\n        svs = np.array(svs)\n        fig, ax = plt.subplots(figsize=(8,5))\n        ax.bar(range(len(svs)), svs, color=\"steelblue\", edgecolor=\"navy\", lw=0.3)\n        ax.axhline(y=1.0, color=\"red\", ls=\"--\", lw=0.8)\n        ax.set_xlabel(\"Mode\"); ax.set_ylabel(\"$\\\\sigma_k$\")\n        ax.set_title(\"Singular Value Spectrum\"); ax.grid(True, alpha=0.3, axis=\"y\")\n        fig.savefig(os.path.join(FIGURES_DIR, \"fig_singular_values.png\"), dpi=300, bbox_inches=\"tight\")\n        plt.close(fig); n_figs += 1\n\n# Eigenvalues CSV\neig_csv = os.path.join(RESULTS_DIR, \"eigenvalues.csv\")\nif os.path.exists(eig_csv):\n    edf = pd.read_csv(eig_csv)\n    if \"magnitude\" in edf.columns:\n        fig, ax = plt.subplots(figsize=(8,5))\n        ax.bar(range(len(edf)), edf[\"magnitude\"], color=\"steelblue\", edgecolor=\"navy\", lw=0.3)\n        ax.axhline(y=1.0, color=\"red\", ls=\"--\", lw=0.8)\n        ax.set_xlabel(\"Mode\"); ax.set_ylabel(\"|$\\\\lambda_k$|\")\n        ax.set_title(\"Eigenvalue Magnitudes\"); ax.grid(True, alpha=0.3, axis=\"y\")\n        fig.savefig(os.path.join(FIGURES_DIR, \"fig_eigenvalue_magnitudes.png\"), dpi=300, bbox_inches=\"tight\")\n        plt.close(fig); n_figs += 1\n\n# Entropy decomposition\nentropy_csv = os.path.join(RESULTS_DIR, \"entropy_decomposition.csv\")\nif os.path.exists(entropy_csv):\n    edf = pd.read_csv(entropy_csv)\n    if \"entropy_production\" in edf.columns:\n        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n        ax1.bar(edf[\"mode\"], edf[\"entropy_production\"], color=\"coral\", edgecolor=\"darkred\", lw=0.5)\n        ax1.set_xlabel(\"Mode\"); ax1.set_ylabel(\"$\\\\sigma_k$\"); ax1.set_title(\"Per-mode Entropy\"); ax1.grid(True, alpha=0.3, axis=\"y\")\n        ax2.bar(edf[\"mode\"], np.cumsum(edf[\"entropy_fraction\"]), color=\"steelblue\", edgecolor=\"navy\", lw=0.5)\n        ax2.set_xlabel(\"Mode\"); ax2.set_ylabel(\"Cumulative Fraction\"); ax2.set_title(\"Cumulative\"); ax2.set_ylim(0,1.05)\n        fig.suptitle(\"Spectral Entropy Decomposition\", fontsize=14)\n        fig.tight_layout()\n        fig.savefig(os.path.join(FIGURES_DIR, \"fig_entropy_decomposition.png\"), dpi=300, bbox_inches=\"tight\")\n        plt.close(fig); n_figs += 1\n\n# Irreversibility field\nirrev_path = os.path.join(RESULTS_DIR, \"irreversibility_field.npy\")\nif os.path.exists(irrev_path):\n    irrev = np.load(irrev_path, allow_pickle=True)\n    fig, ax = plt.subplots(figsize=(14, 4))\n    ax.fill_between(range(len(irrev)), irrev, alpha=0.4, color=\"darkorange\")\n    ax.plot(irrev, lw=0.5, color=\"darkorange\")\n    ax.set_xlabel(\"Time index\"); ax.set_ylabel(\"$I(x)$\"); ax.set_title(\"Irreversibility Field\"); ax.grid(True, alpha=0.3)\n    fig.savefig(os.path.join(FIGURES_DIR, \"fig_irreversibility_field.png\"), dpi=300, bbox_inches=\"tight\")\n    plt.close(fig); n_figs += 1\n\n# Rolling spectral gap vs VIX\nrolling_csv = os.path.join(RESULTS_DIR, \"spectral_gap_timeseries.csv\")\nif os.path.exists(rolling_csv):\n    rdf = pd.read_csv(rolling_csv)\n    if \"spectral_gap\" in rdf.columns:\n        fig, ax1 = plt.subplots(figsize=(14, 5))\n        x = pd.to_datetime(rdf[\"center_date\"]) if \"center_date\" in rdf.columns else range(len(rdf))\n        ax1.plot(x, rdf[\"spectral_gap\"], color=\"steelblue\", lw=1.0, label=\"Spectral Gap\")\n        ax1.set_xlabel(\"Date\"); ax1.set_ylabel(\"Spectral Gap\", color=\"steelblue\")\n        vf = os.path.join(REPO_DIR, \"data\", \"vix.csv\")\n        if os.path.exists(vf):\n            vdf = pd.read_csv(vf, index_col=0, parse_dates=True)\n            vc = \"Close\" if \"Close\" in vdf.columns else vdf.columns[0]\n            ax2 = ax1.twinx()\n            ax2.plot(vdf.index, vdf[vc], color=\"firebrick\", lw=0.8, alpha=0.6, label=\"VIX\")\n            ax2.set_ylabel(\"VIX\", color=\"firebrick\")\n        ax1.set_title(\"Spectral Gap vs VIX\"); ax1.legend(loc=\"upper left\")\n        fig.tight_layout()\n        fig.savefig(os.path.join(FIGURES_DIR, \"fig_spectral_gap_vix.png\"), dpi=300, bbox_inches=\"tight\")\n        plt.close(fig); n_figs += 1\n\n# Baseline comparison\nbaseline_csv = os.path.join(RESULTS_DIR, \"baseline_comparison.csv\")\nif os.path.exists(baseline_csv):\n    bdf = pd.read_csv(baseline_csv)\n    metrics = [m for m in [\"nber_accuracy\",\"nber_f1\",\"nber_precision\",\"nber_recall\"] if m in bdf.columns]\n    if metrics and \"method\" in bdf.columns:\n        fig, ax = plt.subplots(figsize=(10, 6))\n        x = np.arange(len(bdf)); w = 0.8/len(metrics)\n        colors = [\"steelblue\",\"coral\",\"seagreen\",\"orchid\"]\n        for i, m in enumerate(metrics):\n            ax.bar(x+i*w, bdf[m].astype(float), w, label=m.replace(\"nber_\",\"\").title(),\n                   color=colors[i%4], edgecolor=\"black\", lw=0.3)\n        ax.set_xticks(x+w*(len(metrics)-1)/2); ax.set_xticklabels(bdf[\"method\"], rotation=15, ha=\"right\")\n        ax.set_ylabel(\"Score\"); ax.set_title(\"Baseline Comparison\"); ax.legend()\n        ax.set_ylim(0,1.05); ax.grid(True, alpha=0.3, axis=\"y\")\n        fig.tight_layout()\n        fig.savefig(os.path.join(FIGURES_DIR, \"fig_baseline_comparison.png\"), dpi=300, bbox_inches=\"tight\")\n        plt.close(fig); n_figs += 1\n\n# Bootstrap CI + CK\nstat_path = os.path.join(RESULTS_DIR, \"statistical_tests.json\")\nif os.path.exists(stat_path):\n    with open(stat_path) as f:\n        stat = json.load(f)\n    modes_data = stat.get(\"bootstrap_eigenvalue_ci\", {}).get(\"modes\", [])\n    if modes_data:\n        mi = [m[\"mode\"] for m in modes_data]; mn = [m[\"mean_magnitude\"] for m in modes_data]\n        cl = [m[\"ci_lower\"] for m in modes_data]; ch = [m[\"ci_upper\"] for m in modes_data]\n        fig, ax = plt.subplots(figsize=(10,5))\n        ax.errorbar(mi, mn, yerr=[np.array(mn)-np.array(cl), np.array(ch)-np.array(mn)],\n                    fmt=\"o\", capsize=4, color=\"steelblue\", markersize=6)\n        ax.axhline(y=1.0, color=\"red\", ls=\"--\", lw=0.8); ax.set_xlabel(\"Mode\"); ax.set_ylabel(\"|$\\\\lambda_k$|\")\n        ax.set_title(\"Bootstrap Eigenvalue CIs (95%)\"); ax.grid(True, alpha=0.3)\n        fig.savefig(os.path.join(FIGURES_DIR, \"fig_bootstrap_ci.png\"), dpi=300, bbox_inches=\"tight\")\n        plt.close(fig); n_figs += 1\n    ck = stat.get(\"chapman_kolmogorov\", {}); ck_errors = ck.get(\"ck_errors\", [])\n    if ck_errors:\n        fig, ax = plt.subplots(figsize=(8,5))\n        ax.bar([e[\"n\"] for e in ck_errors], [e[\"error\"] for e in ck_errors],\n               color=\"steelblue\", edgecolor=\"navy\", lw=0.5)\n        ax.set_xlabel(\"n (multiples of tau)\"); ax.set_ylabel(\"Mean error\")\n        pv = ck.get(\"p_value\", \"N/A\")\n        ax.set_title(f\"Chapman-Kolmogorov (p={pv:.4f})\" if isinstance(pv, float) else \"Chapman-Kolmogorov\")\n        ax.grid(True, alpha=0.3, axis=\"y\")\n        fig.savefig(os.path.join(FIGURES_DIR, \"fig_chapman_kolmogorov.png\"), dpi=300, bbox_inches=\"tight\")\n        plt.close(fig); n_figs += 1\n\nprint(f\"  Generated {n_figs} figures inline\")\n\n# --- List all result files ---\nprint(f\"\\n  Result files in {RESULTS_DIR}:\")\nif os.path.exists(RESULTS_DIR):\n    for f in sorted(os.listdir(RESULTS_DIR)):\n        sz = os.path.getsize(os.path.join(RESULTS_DIR, f))\n        print(f\"    {sz:>10,} bytes  {f}\")\n\n# --- Final report ---\ntotal_min = (time.time() - pipeline_start) / 60\nn_ok = sum(results.values())\nn_total = len(results)\n\nprint(f\"\\n\\n{'='*70}\")\nprint(f\"  PIPELINE COMPLETE: {n_ok}/{n_total} stages passed ({total_min:.1f} min total)\")\nprint(f\"{'='*70}\")\nfor name, ok in results.items():\n    print(f\"  {'OK' if ok else 'FAIL':6s}  {name}\")\n\n# Print key metrics\nif os.path.exists(analysis_path):\n    with open(analysis_path) as f:\n        r = json.load(f)\n    print(f\"\\n  Key Metrics:\")\n    print(f\"    Spectral gap:         {r.get('spectral_gap', 'N/A')}\")\n    print(f\"    Entropy (empirical):  {r.get('entropy_empirical', 'N/A')} \"\n          f\"[{r.get('entropy_ci_lower', '?')}, {r.get('entropy_ci_upper', '?')}] 95% CI\")\n    print(f\"    Mean irreversibility: {r.get('mean_irreversibility', 'N/A')}\")\n    print(f\"    Irrev method:         {r.get('irrev_method', 'N/A')}\")\n    print(f\"    DB violation:         {r.get('detailed_balance_violation', 'N/A')}\")\n    print(f\"    Complex modes:        {r.get('n_complex_modes', 'N/A')}/{r.get('n_modes', 'N/A')}\")\n    print(f\"    FT ratio:             {r.get('fluctuation_theorem_ratio', 'N/A')}\")\nelse:\n    print(f\"\\n  WARNING: {analysis_path} not found - training may have failed\")\n    print(f\"  Check the STDERR output above for errors\")\nprint(f\"{'='*70}\")\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#@title 3. View figures (run after Cell 2 finishes)\n\nimport glob, os\nfrom IPython.display import Image, display\n\nFIGURES_DIR = \"/content/ktnd_finance/outputs/figures\"\n\npngs = sorted(glob.glob(f\"{FIGURES_DIR}/*.png\"))\nsup_dir = os.path.join(FIGURES_DIR, \"supplemental\")\nif os.path.exists(sup_dir):\n    pngs += sorted(glob.glob(f\"{sup_dir}/*.png\"))\n\nif pngs:\n    print(f\"Found {len(pngs)} figures:\\n\")\n    for p in pngs:\n        print(f\"--- {os.path.basename(p)} ---\")\n        display(Image(filename=p, width=800))\n        print()\nelse:\n    print(\"No figures found. Make sure Cell 2 has finished running first.\")\n    print(f\"Checked: {FIGURES_DIR}\")\n    results_dir = \"/content/ktnd_finance/outputs/results\"\n    if os.path.exists(results_dir):\n        files = os.listdir(results_dir)\n        print(f\"Result files available ({len(files)}): {files}\")\n    else:\n        print(\"No results directory found - Cell 2 needs to run first.\")\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 4. Download all results as zip\n",
    "\n",
    "!cd /content/ktnd_finance && zip -rq /content/ktnd_results.zip outputs/\n",
    "from google.colab import files\n",
    "files.download('/content/ktnd_results.zip')\n",
    "print(\"Download started.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#@title 5. Ablation study (~1-2 hours with 3 seeds) - RECOMMENDED for PRE submission\n\nimport subprocess, time, sys\n\npython = sys.executable\nprint(\"Running 13 ablation variants x 3 seeds...\")\nprint(\"This tests sensitivity to: architecture, n_modes, lag, embedding, dropout,\")\nprint(\"window size, shared weights, loss components, standardization, linear features.\\n\")\n\nt0 = time.time()\nresult = subprocess.run(\n    f'{python} experiments/run_ablations.py --config config/default.yaml --n-seeds 3 --n-jobs 1',\n    shell=True, cwd=\"/content/ktnd_finance\"\n)\nelapsed = (time.time() - t0) / 60\nstatus = 'OK' if result.returncode == 0 else 'FAILED'\nprint(f\"\\nAblations: {status} ({elapsed:.1f} min)\")\n\n# Show summary\nimport pandas as pd, os\nsummary_path = \"/content/ktnd_finance/outputs/results/ablation_summary.csv\"\nif os.path.exists(summary_path):\n    df = pd.read_csv(summary_path)\n    print(f\"\\n{len(df)} ablation variants completed:\")\n    print(df[['name', 'vamp2_mean', 'spectral_gap_mean', 'entropy_total_mean']].to_string(index=False))\n"
  }
 ]
}