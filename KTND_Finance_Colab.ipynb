{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KTND-Finance: Full Experiment Pipeline\n",
    "\n",
    "**Run everything in 2 cells:**\n",
    "1. **Cell 1** (Setup) - Install deps + clone repo (~2 min)\n",
    "2. **Cell 2** (Run All) - Downloads data, trains models, runs baselines/robustness/rolling, generates figures (~2-3 hours)\n",
    "\n",
    "Set runtime to **GPU (T4)** before running: Runtime > Change runtime type > T4 GPU\n",
    "\n",
    "Then hit **Runtime > Run all** and walk away."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 1. Setup (install + clone + verify) - ~2 min\n",
    "\n",
    "# Install missing dependencies (torch/numpy/pandas/scipy/sklearn/matplotlib are pre-installed)\n",
    "!pip install -q yfinance>=1.0.0 hmmlearn>=0.3.0 statsmodels>=0.14.0 arch>=6.0.0 pyyaml>=6.0\n",
    "\n",
    "# Clone repo\n",
    "import os, sys\n",
    "REPO_URL = \"https://github.com/keshavkrishnan08/kind_finance.git\"\n",
    "REPO_DIR = \"/content/ktnd_finance\"\n",
    "\n",
    "if os.path.exists(REPO_DIR):\n",
    "    !cd {REPO_DIR} && git pull\n",
    "else:\n",
    "    !git clone {REPO_URL} {REPO_DIR}\n",
    "\n",
    "os.chdir(REPO_DIR)\n",
    "sys.path.insert(0, REPO_DIR)\n",
    "\n",
    "# Verify\n",
    "import torch, numpy as np\n",
    "from src.model.vampnet import NonEquilibriumVAMPNet\n",
    "print(f\"Python {sys.version.split()[0]} | PyTorch {torch.__version__} | \"\n",
    "      f\"CUDA: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}\")\n",
    "print(\"Setup complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#@title 2. Run ENTIRE experiment pipeline (~2-3 hours) - just run this and walk away\n\nimport subprocess, time, json, os, sys, glob\n\nREPO_DIR = \"/content/ktnd_finance\"\nOUTPUT_DIR = \"/content/ktnd_finance/outputs\"\nRESULTS_DIR = \"/content/ktnd_finance/outputs/results\"\nMODELS_DIR = \"/content/ktnd_finance/outputs/models\"\nFIGURES_DIR = \"/content/ktnd_finance/outputs/figures\"\nDATA_DIR = \"/content/ktnd_finance/data\"\n\nfor d in [OUTPUT_DIR, RESULTS_DIR, MODELS_DIR, FIGURES_DIR]:\n    os.makedirs(d, exist_ok=True)\n\nos.chdir(REPO_DIR)\npython = sys.executable\n\n# Verify paths exist\nprint(f\"Python: {python}\")\nprint(f\"CWD: {os.getcwd()}\")\nprint(f\"Repo dir exists: {os.path.exists(REPO_DIR)}\")\nprint(f\"src/ exists: {os.path.isdir(os.path.join(REPO_DIR, 'src'))}\")\nprint(f\"experiments/ exists: {os.path.isdir(os.path.join(REPO_DIR, 'experiments'))}\")\nprint(f\"config/ exists: {os.path.isdir(os.path.join(REPO_DIR, 'config'))}\")\n\ndef run(name, cmd, check_files=None):\n    \"\"\"Run a stage, print full output, verify files.\"\"\"\n    print(f\"\\n{'='*70}\")\n    print(f\"  STAGE: {name}\")\n    print(f\"  CMD: {cmd}\")\n    print(f\"{'='*70}\")\n    t0 = time.time()\n    result = subprocess.run(cmd, shell=True, cwd=REPO_DIR,\n                            capture_output=True, text=True)\n    elapsed = time.time() - t0\n\n    # Print ALL stdout (not truncated)\n    if result.stdout:\n        for line in result.stdout.strip().split('\\n'):\n            print(f\"  {line}\")\n\n    if result.returncode != 0:\n        print(f\"\\n  === STDERR ===\")\n        if result.stderr:\n            for line in result.stderr.strip().split('\\n'):\n                print(f\"  ! {line}\")\n        print(f\"  >> {name}: FAILED (exit code {result.returncode}, {elapsed/60:.1f} min)\")\n        return False\n\n    # Print any stderr warnings even on success\n    if result.stderr:\n        stderr_lines = result.stderr.strip().split('\\n')\n        # Only print if there are actual errors (not just INFO/WARNING logs)\n        error_lines = [l for l in stderr_lines if 'Error' in l or 'Exception' in l or 'Traceback' in l]\n        if error_lines:\n            print(f\"  === STDERR (errors) ===\")\n            for line in error_lines:\n                print(f\"  ! {line}\")\n\n    # Verify files\n    if check_files:\n        missing = [f for f in check_files if not os.path.exists(f)]\n        if missing:\n            print(f\"  WARNING: Missing expected output files:\")\n            for f in missing:\n                print(f\"    MISSING: {f}\")\n            # Print full stderr to debug\n            if result.stderr:\n                print(f\"  === FULL STDERR ===\")\n                for line in result.stderr.strip().split('\\n')[-30:]:\n                    print(f\"  ! {line}\")\n            print(f\"  >> {name}: INCOMPLETE ({elapsed/60:.1f} min)\")\n            return False\n        for f in check_files:\n            sz = os.path.getsize(f)\n            print(f\"  OK: {os.path.basename(f)} ({sz:,} bytes)\")\n\n    print(f\"  >> {name}: OK ({elapsed/60:.1f} min)\")\n    return True\n\npipeline_start = time.time()\nresults = {}\n\n# --- Stage 1: Quick tests ---\nresults['tests'] = run('Quick tests',\n    f'{python} -m pytest tests/ -q --tb=short -k \"not test_synthetic\"')\n\n# --- Stage 2: Download data ---\nresults['download'] = run('Download data',\n    f'{python} {REPO_DIR}/data/download.py --mode all',\n    check_files=[f'{DATA_DIR}/prices.csv', f'{DATA_DIR}/vix.csv'])\n\n# --- Stage 3: Train univariate (explicit --output-dir) ---\nresults['train_uni'] = run('Train univariate (SPY)',\n    f'{python} {REPO_DIR}/experiments/run_main.py'\n    f' --config config/univariate.yaml --mode univariate --seed 42'\n    f' --output-dir {OUTPUT_DIR}',\n    check_files=[\n        f'{RESULTS_DIR}/analysis_results.json',\n        f'{RESULTS_DIR}/eigenvalues.csv',\n        f'{RESULTS_DIR}/entropy_decomposition.csv',\n        f'{RESULTS_DIR}/irreversibility_field.npy',\n        f'{MODELS_DIR}/vampnet_univariate.pt',\n    ])\n\n# --- Stage 4: Train multiasset (explicit --output-dir) ---\nresults['train_multi'] = run('Train multiasset (11 ETFs)',\n    f'{python} {REPO_DIR}/experiments/run_main.py'\n    f' --config config/multiasset.yaml --mode multiasset --seed 42'\n    f' --output-dir {OUTPUT_DIR}',\n    check_files=[f'{RESULTS_DIR}/analysis_results.json',\n                 f'{MODELS_DIR}/vampnet_multiasset.pt'])\n\n# --- Stage 5: Baselines (explicit --output-dir) ---\nresults['baselines'] = run('Baselines',\n    f'{python} {REPO_DIR}/experiments/run_baselines.py'\n    f' --config config/default.yaml --output-dir {RESULTS_DIR}',\n    check_files=[f'{RESULTS_DIR}/baseline_comparison.csv'])\n\n# --- Stage 6: Robustness (explicit paths) ---\nresults['robustness'] = run('Robustness tests',\n    f'{python} {REPO_DIR}/experiments/run_robustness.py'\n    f' --config config/default.yaml --mode univariate'\n    f' --checkpoint {MODELS_DIR}/vampnet_univariate.pt'\n    f' --output-dir {RESULTS_DIR}',\n    check_files=[f'{RESULTS_DIR}/statistical_tests.json'])\n\n# --- Stage 7: Rolling (explicit paths) ---\nresults['rolling'] = run('Rolling spectral analysis',\n    f'{python} {REPO_DIR}/experiments/run_rolling.py'\n    f' --config config/default.yaml --mode univariate'\n    f' --checkpoint {MODELS_DIR}/vampnet_univariate.pt'\n    f' --output-dir {RESULTS_DIR}',\n    check_files=[f'{RESULTS_DIR}/spectral_gap_timeseries.csv'])\n\n# --- Stage 8: Generate figures via run_figures.py ---\nresults['figures'] = run('Generate figures (script)',\n    f'{python} {REPO_DIR}/experiments/run_figures.py'\n    f' --results-dir {RESULTS_DIR} --figures-dir {FIGURES_DIR}')\n\n# --- Stage 9: Generate figures INLINE as fallback ---\nprint(f\"\\n{'='*70}\")\nprint(f\"  GENERATING FIGURES INLINE (FALLBACK)\")\nprint(f\"{'='*70}\")\n\nimport matplotlib\nmatplotlib.use(\"Agg\")\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\nn_figs = 0\nanalysis_path = f\"{RESULTS_DIR}/analysis_results.json\"\n\nif os.path.exists(analysis_path):\n    with open(analysis_path) as f:\n        ar = json.load(f)\n\n    # Eigenvalue spectrum\n    er, ei = ar.get(\"eigenvalues_real\"), ar.get(\"eigenvalues_imag\")\n    if er and ei:\n        er, ei = np.array(er), np.array(ei)\n        mags = np.sqrt(er**2 + ei**2)\n        fig, ax = plt.subplots(figsize=(7,7))\n        th = np.linspace(0, 2*np.pi, 300)\n        ax.plot(np.cos(th), np.sin(th), \"k--\", lw=0.8, alpha=0.5)\n        sc = ax.scatter(er, ei, c=mags, cmap=\"viridis\", edgecolors=\"k\", linewidths=0.4, s=80, zorder=3)\n        plt.colorbar(sc, ax=ax, label=\"|$\\\\lambda$|\")\n        for i, idx in enumerate(np.argsort(-mags)[:5]):\n            ax.annotate(f\"$\\\\lambda_{i}$\", (er[idx], ei[idx]), textcoords=\"offset points\", xytext=(8,8), fontsize=9)\n        ax.set_xlabel(\"Re($\\\\lambda$)\"); ax.set_ylabel(\"Im($\\\\lambda$)\")\n        ax.set_title(\"Koopman Eigenvalue Spectrum\"); ax.set_aspect(\"equal\"); ax.grid(True, alpha=0.3)\n        fig.savefig(f\"{FIGURES_DIR}/fig1_eigenvalue_spectrum.png\", dpi=300, bbox_inches=\"tight\"); plt.close(fig); n_figs += 1\n\n    svs = ar.get(\"singular_values\")\n    if svs:\n        fig, ax = plt.subplots(figsize=(8,5))\n        ax.bar(range(len(svs)), svs, color=\"steelblue\", edgecolor=\"navy\", lw=0.3)\n        ax.axhline(y=1.0, color=\"red\", ls=\"--\", lw=0.8)\n        ax.set_xlabel(\"Mode\"); ax.set_ylabel(\"$\\\\sigma_k$\"); ax.set_title(\"Singular Value Spectrum\"); ax.grid(True, alpha=0.3, axis=\"y\")\n        fig.savefig(f\"{FIGURES_DIR}/fig_singular_values.png\", dpi=300, bbox_inches=\"tight\"); plt.close(fig); n_figs += 1\nelse:\n    print(f\"  analysis_results.json NOT FOUND at {analysis_path}\")\n\nfor csv_name, title, ycol in [\n    (\"eigenvalues.csv\", \"Eigenvalue Magnitudes\", \"magnitude\"),\n    (\"entropy_decomposition.csv\", \"Entropy Decomposition\", \"entropy_production\"),\n]:\n    p = f\"{RESULTS_DIR}/{csv_name}\"\n    if os.path.exists(p):\n        df = pd.read_csv(p)\n        if ycol in df.columns:\n            fig, ax = plt.subplots(figsize=(8,5))\n            ax.bar(df[\"mode\"], df[ycol], color=\"coral\" if \"entropy\" in csv_name else \"steelblue\", edgecolor=\"black\", lw=0.3)\n            ax.set_xlabel(\"Mode\"); ax.set_ylabel(ycol); ax.set_title(title); ax.grid(True, alpha=0.3, axis=\"y\")\n            fig.savefig(f\"{FIGURES_DIR}/fig_{csv_name.replace('.csv','')}.png\", dpi=300, bbox_inches=\"tight\"); plt.close(fig); n_figs += 1\n\nirp = f\"{RESULTS_DIR}/irreversibility_field.npy\"\nif os.path.exists(irp):\n    ir = np.load(irp, allow_pickle=True)\n    fig, ax = plt.subplots(figsize=(14,4))\n    ax.fill_between(range(len(ir)), ir, alpha=0.4, color=\"darkorange\"); ax.plot(ir, lw=0.5, color=\"darkorange\")\n    ax.set_xlabel(\"Time\"); ax.set_ylabel(\"$I(x)$\"); ax.set_title(\"Irreversibility Field\"); ax.grid(True, alpha=0.3)\n    fig.savefig(f\"{FIGURES_DIR}/fig_irreversibility_field.png\", dpi=300, bbox_inches=\"tight\"); plt.close(fig); n_figs += 1\n\nrcp = f\"{RESULTS_DIR}/spectral_gap_timeseries.csv\"\nif os.path.exists(rcp):\n    rdf = pd.read_csv(rcp)\n    if \"spectral_gap\" in rdf.columns:\n        fig, ax = plt.subplots(figsize=(14,5))\n        x = pd.to_datetime(rdf[\"center_date\"]) if \"center_date\" in rdf.columns else range(len(rdf))\n        ax.plot(x, rdf[\"spectral_gap\"], color=\"steelblue\", lw=1.0)\n        ax.set_xlabel(\"Date\"); ax.set_ylabel(\"Spectral Gap\"); ax.set_title(\"Rolling Spectral Gap\"); ax.grid(True, alpha=0.3)\n        fig.savefig(f\"{FIGURES_DIR}/fig_spectral_gap.png\", dpi=300, bbox_inches=\"tight\"); plt.close(fig); n_figs += 1\n\nbcp = f\"{RESULTS_DIR}/baseline_comparison.csv\"\nif os.path.exists(bcp):\n    bdf = pd.read_csv(bcp)\n    ms = [m for m in [\"nber_accuracy\",\"nber_f1\",\"nber_precision\",\"nber_recall\"] if m in bdf.columns]\n    if ms and \"method\" in bdf.columns:\n        fig, ax = plt.subplots(figsize=(10,6))\n        x = np.arange(len(bdf)); w = 0.8/len(ms)\n        for i, m in enumerate(ms):\n            ax.bar(x+i*w, bdf[m].astype(float), w, label=m.replace(\"nber_\",\"\").title(),\n                   color=[\"steelblue\",\"coral\",\"seagreen\",\"orchid\"][i%4], edgecolor=\"black\", lw=0.3)\n        ax.set_xticks(x+w*(len(ms)-1)/2); ax.set_xticklabels(bdf[\"method\"], rotation=15, ha=\"right\")\n        ax.set_ylabel(\"Score\"); ax.set_title(\"Baseline Comparison\"); ax.legend(); ax.set_ylim(0,1.05)\n        fig.savefig(f\"{FIGURES_DIR}/fig_baseline_comparison.png\", dpi=300, bbox_inches=\"tight\"); plt.close(fig); n_figs += 1\n\nprint(f\"  Generated {n_figs} figures inline\")\n\n# --- List ALL output files ---\nprint(f\"\\n{'='*70}\")\nprint(f\"  ALL OUTPUT FILES\")\nprint(f\"{'='*70}\")\nfor dirpath, dirnames, filenames in os.walk(OUTPUT_DIR):\n    for f in sorted(filenames):\n        fp = os.path.join(dirpath, f)\n        sz = os.path.getsize(fp)\n        rel = os.path.relpath(fp, OUTPUT_DIR)\n        print(f\"  {sz:>10,} bytes  {rel}\")\n\n# --- Final report ---\ntotal_min = (time.time() - pipeline_start) / 60\nn_ok = sum(results.values())\nn_total = len(results)\n\nprint(f\"\\n{'='*70}\")\nprint(f\"  PIPELINE COMPLETE: {n_ok}/{n_total} stages passed ({total_min:.1f} min total)\")\nprint(f\"{'='*70}\")\nfor name, ok in results.items():\n    print(f\"  {'OK' if ok else 'FAIL':6s}  {name}\")\n\nif os.path.exists(analysis_path):\n    with open(analysis_path) as f:\n        r = json.load(f)\n    print(f\"\\n  Key Metrics:\")\n    print(f\"    Spectral gap:         {r.get('spectral_gap', 'N/A')}\")\n    print(f\"    Entropy (empirical):  {r.get('entropy_empirical', 'N/A')} \"\n          f\"[{r.get('entropy_ci_lower', '?')}, {r.get('entropy_ci_upper', '?')}] 95% CI\")\n    print(f\"    Mean irreversibility: {r.get('mean_irreversibility', 'N/A')}\")\n    print(f\"    Irrev method:         {r.get('irrev_method', 'N/A')}\")\n    print(f\"    DB violation:         {r.get('detailed_balance_violation', 'N/A')}\")\n    print(f\"    Complex modes:        {r.get('n_complex_modes', 'N/A')}/{r.get('n_modes', 'N/A')}\")\n    print(f\"    FT ratio:             {r.get('fluctuation_theorem_ratio', 'N/A')}\")\nelse:\n    print(f\"\\n  WARNING: No analysis_results.json found!\")\n    print(f\"  Check STDERR output above for the actual error.\")\nprint(f\"{'='*70}\")\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#@title 3. View figures (run after Cell 2 finishes)\n\nimport glob, os\nfrom IPython.display import Image, display\n\nFIGURES_DIR = \"/content/ktnd_finance/outputs/figures\"\n\npngs = sorted(glob.glob(f\"{FIGURES_DIR}/*.png\"))\nsup_dir = os.path.join(FIGURES_DIR, \"supplemental\")\nif os.path.exists(sup_dir):\n    pngs += sorted(glob.glob(f\"{sup_dir}/*.png\"))\n\nif pngs:\n    print(f\"Found {len(pngs)} figures:\\n\")\n    for p in pngs:\n        print(f\"--- {os.path.basename(p)} ---\")\n        display(Image(filename=p, width=800))\n        print()\nelse:\n    print(\"No figures found. Make sure Cell 2 has finished running first.\")\n    print(f\"Checked: {FIGURES_DIR}\")\n    results_dir = \"/content/ktnd_finance/outputs/results\"\n    if os.path.exists(results_dir):\n        files = os.listdir(results_dir)\n        print(f\"Result files available ({len(files)}): {files}\")\n    else:\n        print(\"No results directory found - Cell 2 needs to run first.\")\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 4. Download all results as zip\n",
    "\n",
    "!cd /content/ktnd_finance && zip -rq /content/ktnd_results.zip outputs/\n",
    "from google.colab import files\n",
    "files.download('/content/ktnd_results.zip')\n",
    "print(\"Download started.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#@title 5. Ablation study (~1-2 hours with 3 seeds) - RECOMMENDED for PRE submission\n\nimport subprocess, time, sys\n\npython = sys.executable\nprint(\"Running 13 ablation variants x 3 seeds...\")\nprint(\"This tests sensitivity to: architecture, n_modes, lag, embedding, dropout,\")\nprint(\"window size, shared weights, loss components, standardization, linear features.\\n\")\n\nt0 = time.time()\nresult = subprocess.run(\n    f'{python} experiments/run_ablations.py --config config/default.yaml --n-seeds 3 --n-jobs 1',\n    shell=True, cwd=\"/content/ktnd_finance\"\n)\nelapsed = (time.time() - t0) / 60\nstatus = 'OK' if result.returncode == 0 else 'FAILED'\nprint(f\"\\nAblations: {status} ({elapsed:.1f} min)\")\n\n# Show summary\nimport pandas as pd, os\nsummary_path = \"/content/ktnd_finance/outputs/results/ablation_summary.csv\"\nif os.path.exists(summary_path):\n    df = pd.read_csv(summary_path)\n    print(f\"\\n{len(df)} ablation variants completed:\")\n    print(df[['name', 'vamp2_mean', 'spectral_gap_mean', 'entropy_total_mean']].to_string(index=False))\n"
  }
 ]
}